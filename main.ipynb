{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543ae626",
   "metadata": {},
   "source": [
    "# $\\text{Import data}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6c5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4406d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3156, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3121</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>service</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2777</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2534</td>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  \\\n",
       "0  3121               But the staff was so horrible to us.   \n",
       "1  2777  To be completely fair, the only redeeming fact...   \n",
       "2  2777  To be completely fair, the only redeeming fact...   \n",
       "3  1634  The food is uniformly exceptional, with a very...   \n",
       "4  2534  Where Gabriela personaly greets you and recomm...   \n",
       "\n",
       "            aspectCategory  polarity  \n",
       "0                  service  negative  \n",
       "1                     food  positive  \n",
       "2  anecdotes/miscellaneous  negative  \n",
       "3                     food  positive  \n",
       "4                  service  positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"contest1_train.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9cebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dups(df, name:str):\n",
    "    if any(df.duplicated()):\n",
    "        dups = df[df.duplicated()]\n",
    "\n",
    "        print(f'{name}\\t There are {len(dups)} dups')\n",
    "\n",
    "        is_drop = input(\"type 'y' to drop:\")\n",
    "        if is_drop == 'y':\n",
    "            print(\"dropping...\\n\")\n",
    "            return df.drop_duplicates()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47414cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data\t There are 2 dups\n",
      "type 'y' to drop:y\n",
      "dropping...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = drop_dups(df, \"Whole data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb04870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect\t There are 2 dups\n",
      "type 'y' to drop:y\n",
      "dropping...\n",
      "\n",
      "sentiment\t There are 427 dups\n",
      "type 'y' to drop:y\n",
      "dropping...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_aspect = df[['text', 'aspectCategory']]\n",
    "df_sentiment = df[['text', 'polarity']]\n",
    "\n",
    "df_aspect = drop_dups(df_aspect, \"aspect\")\n",
    "df_sentiment = drop_dups(df_sentiment, \"sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd878044",
   "metadata": {},
   "source": [
    "# $\\text{1. Sentiment}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de250e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_models import utils, sentiment\n",
    "\n",
    "# Drop texts that are duplicated\n",
    "df_sentiment = df_sentiment.drop_duplicates(subset=['text'], keep='last')\n",
    "\n",
    "X_TRAIN_sent, X_DEV_sent, Y_TRAIN_sent, Y_DEV_sent = utils.split_data(df_sentiment['text'], df_sentiment['polarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c8e75",
   "metadata": {},
   "source": [
    "## 1.1) Rule-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8e0c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.50      0.01      0.01       148\n",
      "    negative       0.79      0.03      0.06       602\n",
      "     neutral       0.15      0.98      0.26       354\n",
      "    positive       0.94      0.14      0.24      1478\n",
      "\n",
      "    accuracy                           0.22      2582\n",
      "   macro avg       0.60      0.29      0.14      2582\n",
      "weighted avg       0.77      0.22      0.19      2582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sentiment.VADER(df_sentiment['text'])\n",
    "utils.get_reports(y_true = df_sentiment['polarity'], y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0828e9",
   "metadata": {},
   "source": [
    "## 1.2) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce6714c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vectorizer...\n",
      "TF-IDF matrix: (2065, 3589)\n"
     ]
    }
   ],
   "source": [
    "logreg = sentiment.LOGREG()\n",
    "\n",
    "X_train_sent = logreg.preprocess(X_TRAIN_sent.values)\n",
    "X_dev_sent = logreg.preprocess(X_DEV_sent.values)\n",
    "\n",
    "logreg.fit(X_train_sent, Y_TRAIN_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89430a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        30\n",
      "    negative       0.66      0.42      0.52       120\n",
      "     neutral       0.91      0.14      0.24        71\n",
      "    positive       0.67      0.96      0.79       296\n",
      "\n",
      "    accuracy                           0.67       517\n",
      "   macro avg       0.56      0.38      0.39       517\n",
      "weighted avg       0.66      0.67      0.61       517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_dev_sent)\n",
    "utils.get_reports(y_true = Y_DEV_sent, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b8bb6b",
   "metadata": {},
   "source": [
    "## 1.3) Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ef29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, GRU, Bidirectional\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_rnn_sentiment(vocab_size, emb_dim, n_rnn_layers, n_dense_layers, n_outputs):\n",
    "    layers = [ Embedding(input_dim=vocab_size, output_dim=emb_dim, mask_zero=True) ]\n",
    "    \n",
    "    for i in range(n_rnn_layers-1):\n",
    "        layers.append( Bidirectional(GRU(64, dropout=0.5, return_sequences=True)) )\n",
    "    layers.append( Bidirectional(GRU(64, dropout=0.5, return_sequences=False)) )\n",
    "        \n",
    "    for i in range(n_dense_layers):\n",
    "        layers.append( Dense(64, activation='relu') )\n",
    "    layers.append( Dense(n_outputs, activation='sigmoid') )   ## activation sofmax??\n",
    "    \n",
    "    model = tf.keras.models.Sequential(layers)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ade884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_rnn_sentiment(\n",
    "    vocab_size = 5000,\n",
    "    emb_dim = 64,\n",
    "    n_rnn_layers = 3,\n",
    "    n_dense_layers = 1,\n",
    "    n_outputs = len(Y_TRAIN_sent.unique())\n",
    ")\n",
    "\n",
    "rnn = sentiment.RNN(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0fa61bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Build new Tokenizer\n",
      "...Build new LabelEncoder\n"
     ]
    }
   ],
   "source": [
    "X_train_sent, Y_train_sent = rnn.preprocess(X_TRAIN_sent.values, Y_TRAIN_sent.values, vocab_size = 5000, maxlen=30)\n",
    "X_dev_sent, Y_dev_sent = rnn.preprocess(X_DEV_sent.values, Y_DEV_sent.values, vocab_size = 5000, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcff1175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "65/65 [==============================] - 29s 172ms/step - loss: 1.1461 - accuracy: 0.5603 - val_loss: 1.0580 - val_accuracy: 0.5725\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 4s 68ms/step - loss: 0.9087 - accuracy: 0.6189 - val_loss: 0.9516 - val_accuracy: 0.6325\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 5s 69ms/step - loss: 0.6905 - accuracy: 0.7225 - val_loss: 0.9590 - val_accuracy: 0.6248\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 5s 72ms/step - loss: 0.5822 - accuracy: 0.7545 - val_loss: 1.0140 - val_accuracy: 0.6344\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 5s 70ms/step - loss: 0.5030 - accuracy: 0.7792 - val_loss: 1.2399 - val_accuracy: 0.6248\n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(\n",
    "    X_train_sent, Y_train_sent, X_dev_sent, Y_dev_sent,\n",
    "    batch_size = 32, epochs = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edd2a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        30\n",
      "    negative       0.44      0.72      0.54       120\n",
      "     neutral       0.00      0.00      0.00        71\n",
      "    positive       0.76      0.80      0.78       296\n",
      "\n",
      "    accuracy                           0.62       517\n",
      "   macro avg       0.30      0.38      0.33       517\n",
      "weighted avg       0.54      0.62      0.57       517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rnn.predict(X_dev_sent)\n",
    "utils.get_reports(\n",
    "    y_true = [rnn.le.classes_[i] for i in Y_dev_sent], \n",
    "    y_pred= [rnn.le.classes_[i] for i in y_pred]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdf22d",
   "metadata": {},
   "source": [
    "# $\\text{2. Aspect}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "395e41bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['service' 'food' 'anecdotes/miscellaneous' 'price' 'ambience']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>service</th>\n",
       "      <th>food</th>\n",
       "      <th>anecdotes/miscellaneous</th>\n",
       "      <th>price</th>\n",
       "      <th>ambience</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$160 for 2 filets, 2 sides, an appetizer and drinks.</th>\n",
       "      <td>[food, price]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$20 for all you can eat sushi cannot be beaten.</th>\n",
       "      <td>[price]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$20 gets you unlimited sushi of a very high quality- I even took a friend here from Japan who said it was one of the best sushi places in the US that he has been to.</th>\n",
       "      <td>[food, price]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>($200 for 2 glasses of champagne, not too expensive bottle of wine and 2 after dinner drinks).</th>\n",
       "      <td>[price]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Always ask the bartender for the SEASONAL beer!!!</th>\n",
       "      <td>[food]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   aspectCategory  service  \\\n",
       "text                                                                         \n",
       "$160 for 2 filets, 2 sides, an appetizer and dr...  [food, price]        0   \n",
       "$20 for all you can eat sushi cannot be beaten.           [price]        0   \n",
       "$20 gets you unlimited sushi of a very high qua...  [food, price]        0   \n",
       "($200 for 2 glasses of champagne, not too expen...        [price]        0   \n",
       "(Always ask the bartender for the SEASONAL beer!!!         [food]        0   \n",
       "\n",
       "                                                    food  \\\n",
       "text                                                       \n",
       "$160 for 2 filets, 2 sides, an appetizer and dr...     1   \n",
       "$20 for all you can eat sushi cannot be beaten.        0   \n",
       "$20 gets you unlimited sushi of a very high qua...     1   \n",
       "($200 for 2 glasses of champagne, not too expen...     0   \n",
       "(Always ask the bartender for the SEASONAL beer!!!     1   \n",
       "\n",
       "                                                    anecdotes/miscellaneous  \\\n",
       "text                                                                          \n",
       "$160 for 2 filets, 2 sides, an appetizer and dr...                        0   \n",
       "$20 for all you can eat sushi cannot be beaten.                           0   \n",
       "$20 gets you unlimited sushi of a very high qua...                        0   \n",
       "($200 for 2 glasses of champagne, not too expen...                        0   \n",
       "(Always ask the bartender for the SEASONAL beer!!!                        0   \n",
       "\n",
       "                                                    price  ambience  \n",
       "text                                                                 \n",
       "$160 for 2 filets, 2 sides, an appetizer and dr...      1         0  \n",
       "$20 for all you can eat sushi cannot be beaten.         1         0  \n",
       "$20 gets you unlimited sushi of a very high qua...      1         0  \n",
       "($200 for 2 glasses of champagne, not too expen...      1         0  \n",
       "(Always ask the bartender for the SEASONAL beer!!!      0         0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.pivot_table(\n",
    "                df_aspect,\n",
    "                index='text',\n",
    "                values='aspectCategory',\n",
    "                aggfunc=lambda x: list(x)\n",
    "            )\n",
    "\n",
    "aspects = df_aspect.aspectCategory.unique()\n",
    "print(aspects)\n",
    "\n",
    "for a in aspects:\n",
    "    temp_df[a] = temp_df.apply(lambda x: 1 if a in x.aspectCategory else 0, axis=1)\n",
    "    \n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15363522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_asp, X_DEV_asp, Y_TRAIN_asp, Y_DEV_asp = utils.split_data(temp_df.index, temp_df.iloc[:, -5:], stratify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62d2cd",
   "metadata": {},
   "source": [
    "## 2.1) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd632e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new models\n",
      "Creating new vectorizer...\n",
      "TF-IDF matrix: (2065, 3633)\n"
     ]
    }
   ],
   "source": [
    "from my_models import aspect\n",
    "\n",
    "logreg_aspect = aspect.MulBinary_logreg()\n",
    "X_train_asp = logreg_aspect.preprocess(X_TRAIN_asp, Y_TRAIN_asp)\n",
    "X_dev_asp = logreg_aspect.preprocess(X_DEV_asp, Y_DEV_asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39e2e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_aspect.fit(X_train_asp, Y_TRAIN_asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "070bb966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting service...\n",
      "predicting food...\n",
      "predicting anecdotes/miscellaneous...\n",
      "predicting price...\n",
      "predicting ambience...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = logreg_aspect.predict(X_dev_asp)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac36607c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65       106\n",
      "           1       0.91      0.72      0.80       209\n",
      "           2       0.83      0.59      0.69       191\n",
      "           3       0.89      0.14      0.25        56\n",
      "           4       0.89      0.11      0.20        73\n",
      "\n",
      "   micro avg       0.89      0.52      0.66       635\n",
      "   macro avg       0.90      0.41      0.52       635\n",
      "weighted avg       0.90      0.52      0.62       635\n",
      " samples avg       0.59      0.55      0.56       635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "utils.get_reports(\n",
    "    y_true = Y_DEV_asp.values, \n",
    "    y_pred= outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8adf12",
   "metadata": {},
   "source": [
    "## 2.2) Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72f52440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_asp(vocab_size, emb_dim, n_rnn_layers, n_dense_layers):\n",
    "    layers = [ Embedding(input_dim=vocab_size, output_dim=emb_dim, mask_zero=True) ]\n",
    "    \n",
    "    for i in range(n_rnn_layers-1):\n",
    "        layers.append( Bidirectional(GRU(64, dropout=0.5, return_sequences=True)) )\n",
    "    layers.append( Bidirectional(GRU(64, dropout=0.5, return_sequences=False)) )\n",
    "        \n",
    "    for i in range(n_dense_layers):\n",
    "        layers.append( Dense(64, activation='relu') )\n",
    "    layers.append( Dense(1, activation='sigmoid') )\n",
    "    \n",
    "    model = tf.keras.models.Sequential(layers)\n",
    "    model.compile()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59192f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_template_model = get_rnn_asp(\n",
    "    vocab_size = 5000,\n",
    "    emb_dim = 64,\n",
    "    n_rnn_layers = 3,\n",
    "    n_dense_layers = 1\n",
    ")\n",
    "multi_binary = aspect.MulBinary_rnn(compiled_template_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "319be748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Build new Tokenizer\n",
      "cloning model from template...\n"
     ]
    }
   ],
   "source": [
    "X_train_asp, Y_train_asp = multi_binary.preprocess(X_TRAIN_asp, Y_TRAIN_asp, vocab_size = 5000, maxlen=30)\n",
    "X_dev_asp, Y_dev_asp = multi_binary.preprocess(X_DEV_asp, Y_DEV_asp, vocab_size = 5000, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49dac7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting service ...\n",
      "\n",
      "Epoch 1/3\n",
      "65/65 [==============================] - 30s 194ms/step - loss: 0.4815 - accuracy: 0.8150 - val_loss: 0.3615 - val_accuracy: 0.8704\n",
      "Epoch 2/3\n",
      "65/65 [==============================] - 6s 92ms/step - loss: 0.2131 - accuracy: 0.9201 - val_loss: 0.2643 - val_accuracy: 0.8936\n",
      "Epoch 3/3\n",
      "65/65 [==============================] - 6s 95ms/step - loss: 0.0804 - accuracy: 0.9753 - val_loss: 0.3028 - val_accuracy: 0.8859\n",
      "fitting food ...\n",
      "\n",
      "Epoch 1/3\n",
      "65/65 [==============================] - 38s 246ms/step - loss: 0.6059 - accuracy: 0.6697 - val_loss: 0.4122 - val_accuracy: 0.8356\n",
      "Epoch 2/3\n",
      "65/65 [==============================] - 7s 105ms/step - loss: 0.2620 - accuracy: 0.9012 - val_loss: 0.3092 - val_accuracy: 0.8569\n",
      "Epoch 3/3\n",
      "65/65 [==============================] - 7s 113ms/step - loss: 0.1219 - accuracy: 0.9569 - val_loss: 0.3382 - val_accuracy: 0.8607\n",
      "fitting anecdotes/miscellaneous ...\n",
      "\n",
      "Epoch 1/3\n",
      "65/65 [==============================] - 43s 323ms/step - loss: 0.5683 - accuracy: 0.6794 - val_loss: 0.5201 - val_accuracy: 0.7447\n",
      "Epoch 2/3\n",
      "65/65 [==============================] - 7s 105ms/step - loss: 0.3269 - accuracy: 0.8581 - val_loss: 0.3979 - val_accuracy: 0.8337\n",
      "Epoch 3/3\n",
      "65/65 [==============================] - 7s 106ms/step - loss: 0.1978 - accuracy: 0.9215 - val_loss: 0.4772 - val_accuracy: 0.8279\n",
      "fitting price ...\n",
      "\n",
      "Epoch 1/3\n",
      "65/65 [==============================] - 40s 245ms/step - loss: 0.3912 - accuracy: 0.8736 - val_loss: 0.3239 - val_accuracy: 0.8917\n",
      "Epoch 2/3\n",
      "65/65 [==============================] - 7s 106ms/step - loss: 0.2139 - accuracy: 0.9269 - val_loss: 0.2374 - val_accuracy: 0.9110\n",
      "Epoch 3/3\n",
      "65/65 [==============================] - 7s 106ms/step - loss: 0.0725 - accuracy: 0.9743 - val_loss: 0.2083 - val_accuracy: 0.9400\n",
      "fitting ambience ...\n",
      "\n",
      "Epoch 1/3\n",
      "65/65 [==============================] - 40s 249ms/step - loss: 0.4378 - accuracy: 0.8571 - val_loss: 0.3770 - val_accuracy: 0.8588\n",
      "Epoch 2/3\n",
      "65/65 [==============================] - 8s 123ms/step - loss: 0.2438 - accuracy: 0.9036 - val_loss: 0.3003 - val_accuracy: 0.8936\n",
      "Epoch 3/3\n",
      "65/65 [==============================] - 8s 121ms/step - loss: 0.0965 - accuracy: 0.9632 - val_loss: 0.2856 - val_accuracy: 0.8897\n"
     ]
    }
   ],
   "source": [
    "histories = multi_binary.fit(\n",
    "                X_train_asp, Y_train_asp, X_dev_asp, Y_dev_asp,\n",
    "                batch_size = 32, epochs = 3\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4613c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting service...\n",
      "predicting food...\n",
      "predicting anecdotes/miscellaneous...\n",
      "predicting price...\n",
      "predicting ambience...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       106\n",
      "           1       0.83      0.83      0.83       209\n",
      "           2       0.83      0.67      0.74       191\n",
      "           3       0.75      0.68      0.71        56\n",
      "           4       0.60      0.64      0.62        73\n",
      "\n",
      "   micro avg       0.77      0.74      0.75       635\n",
      "   macro avg       0.74      0.72      0.73       635\n",
      "weighted avg       0.77      0.74      0.75       635\n",
      " samples avg       0.73      0.75      0.72       635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "outputs = multi_binary.predict(X_dev_asp)\n",
    "utils.get_reports(\n",
    "    y_true = Y_dev_asp.values, \n",
    "    y_pred= outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdba5d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting service...\n",
      "predicting food...\n",
      "predicting anecdotes/miscellaneous...\n",
      "predicting price...\n",
      "predicting ambience...\n"
     ]
    }
   ],
   "source": [
    "from my_models import inference\n",
    "inferencer = inference.InferenceModel(logreg, multi_binary)\n",
    "\n",
    "df_test = pd.read_csv(\"contest1_test.csv\")\n",
    "\n",
    "df_train_inference = df_test[['id','text']]\n",
    "outputs = inferencer.predict(df_train_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "423e7b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>ambience</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>587 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               aspectCategory  polarity\n",
       "id                                     \n",
       "899                   service  positive\n",
       "899                      food  positive\n",
       "1349  anecdotes/miscellaneous  positive\n",
       "1349                 ambience  positive\n",
       "934                      food  positive\n",
       "...                       ...       ...\n",
       "1063  anecdotes/miscellaneous  positive\n",
       "777                      food  positive\n",
       "875   anecdotes/miscellaneous  positive\n",
       "671                      food  positive\n",
       "617   anecdotes/miscellaneous  positive\n",
       "\n",
       "[587 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c064f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.to_csv(\"test-pred-1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
