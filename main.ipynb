{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543ae626",
   "metadata": {},
   "source": [
    "# $\\text{Import data}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4406d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3156, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3121</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>service</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2777</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2534</td>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  \\\n",
       "0  3121               But the staff was so horrible to us.   \n",
       "1  2777  To be completely fair, the only redeeming fact...   \n",
       "2  2777  To be completely fair, the only redeeming fact...   \n",
       "3  1634  The food is uniformly exceptional, with a very...   \n",
       "4  2534  Where Gabriela personaly greets you and recomm...   \n",
       "\n",
       "            aspectCategory  polarity  \n",
       "0                  service  negative  \n",
       "1                     food  positive  \n",
       "2  anecdotes/miscellaneous  negative  \n",
       "3                     food  positive  \n",
       "4                  service  positive  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from my_models.inference import get_rnn, get_cnn\n",
    "\n",
    "df = pd.read_csv(\"contest1_train.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f842dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_models import utils\n",
    "\n",
    "emb_dim = 100\n",
    "vocab, embedding_matrix = utils.get_embeddings(emb_dim)\n",
    "\n",
    "maxlen = 30\n",
    "vocab_size = embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9cebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dups(df, name:str):\n",
    "    if any(df.duplicated()):\n",
    "        dups = df[df.duplicated()]\n",
    "        return df.drop_duplicates()\n",
    "    \n",
    "df = drop_dups(df, \"Whole data\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "TRAIN, DEV = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "df_aspect = TRAIN[['id','text', 'aspectCategory']]\n",
    "df_sentiment = TRAIN[['id','text', 'polarity']]\n",
    "\n",
    "df_aspect = drop_dups(df_aspect, \"aspect\")\n",
    "df_sentiment = drop_dups(df_sentiment, \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf1cb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV.to_csv('DEV.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71cdaea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1315</td>\n",
       "      <td>Amma has the worst value for money I have expe...</td>\n",
       "      <td>price</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576</td>\n",
       "      <td>By far the best salad I have had in a fast foo...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2850</td>\n",
       "      <td>The food was amazing, the service was so atten...</td>\n",
       "      <td>ambience</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>There was a long wait for a table outside, but...</td>\n",
       "      <td>service</td>\n",
       "      <td>conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>Having hunted around for a quiet, romantic, ye...</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>1082</td>\n",
       "      <td>So, the menu is written in chalk above your he...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>3243</td>\n",
       "      <td>Hopefully next time, I will save room for dess...</td>\n",
       "      <td>food</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>1191</td>\n",
       "      <td>Knowledge of the chef and the waitress are bel...</td>\n",
       "      <td>food</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>1380</td>\n",
       "      <td>Definately check it out!!!</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>812</td>\n",
       "      <td>The food was delicious and the waiter was incr...</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>789 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0    1315  Amma has the worst value for money I have expe...   \n",
       "1    2576  By far the best salad I have had in a fast foo...   \n",
       "2    2850  The food was amazing, the service was so atten...   \n",
       "3     301  There was a long wait for a table outside, but...   \n",
       "4      87  Having hunted around for a quiet, romantic, ye...   \n",
       "..    ...                                                ...   \n",
       "784  1082  So, the menu is written in chalk above your he...   \n",
       "785  3243  Hopefully next time, I will save room for dess...   \n",
       "786  1191  Knowledge of the chef and the waitress are bel...   \n",
       "787  1380                         Definately check it out!!!   \n",
       "788   812  The food was delicious and the waiter was incr...   \n",
       "\n",
       "              aspectCategory  polarity  \n",
       "0                      price  negative  \n",
       "1                       food  positive  \n",
       "2                   ambience  positive  \n",
       "3                    service  conflict  \n",
       "4    anecdotes/miscellaneous   neutral  \n",
       "..                       ...       ...  \n",
       "784                     food  positive  \n",
       "785                     food   neutral  \n",
       "786                     food  negative  \n",
       "787  anecdotes/miscellaneous  positive  \n",
       "788                  service  positive  \n",
       "\n",
       "[789 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"DEV.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd878044",
   "metadata": {},
   "source": [
    "# $\\text{1. Sentiment}$\n",
    "- Rule-based\n",
    "- BOW\n",
    "- TF-IDF\n",
    "- Bidirectional GRU\n",
    "- CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de250e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_models import sentiment\n",
    "\n",
    "# Drop texts that are duplicated\n",
    "df_sentiment = df_sentiment.drop_duplicates(subset=['text'], keep='first')\n",
    "\n",
    "X_TRAIN_sent, X_DEV_sent, Y_TRAIN_sent, Y_DEV_sent = TRAIN['text'], DEV['text'], TRAIN['polarity'], DEV['polarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c8e75",
   "metadata": {},
   "source": [
    "## 1.1) Rule-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8e0c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.50      0.01      0.01       148\n",
      "    negative       0.79      0.03      0.06       602\n",
      "     neutral       0.15      0.98      0.26       354\n",
      "    positive       0.94      0.14      0.24      1478\n",
      "\n",
      "    accuracy                           0.22      2582\n",
      "   macro avg       0.60      0.29      0.14      2582\n",
      "weighted avg       0.77      0.22      0.19      2582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sentiment.VADER(df_sentiment['text'])\n",
    "utils.get_reports(y_true = df_sentiment['polarity'], y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0828e9",
   "metadata": {},
   "source": [
    "## 1.2) Logistic regression (bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6714c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new BOW vectorizer...\n",
      "BOW matrix: (2365, 3570)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.29      0.13      0.18        47\n",
      "    negative       0.59      0.48      0.53       178\n",
      "     neutral       0.45      0.30      0.36       100\n",
      "    positive       0.75      0.89      0.81       464\n",
      "\n",
      "    accuracy                           0.68       789\n",
      "   macro avg       0.52      0.45      0.47       789\n",
      "weighted avg       0.65      0.68      0.65       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_sent_bow = sentiment.ml(feature_mode=\"BOW\", model=LogisticRegression, max_iter=200)\n",
    "# preprocess\n",
    "X_train_sent = logreg_sent_bow.preprocess(X_TRAIN_sent.values)\n",
    "X_dev_sent = logreg_sent_bow.preprocess(X_DEV_sent.values)\n",
    "\n",
    "# train\n",
    "logreg_sent_bow.fit(X_train_sent, Y_TRAIN_sent)\n",
    "\n",
    "# inference\n",
    "y_pred = logreg_sent_bow.predict(X_dev_sent)\n",
    "utils.get_reports(y_true = Y_DEV_sent, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a1d6db",
   "metadata": {},
   "source": [
    "## 1.3) Logistic regression (tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89430a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new TFIDF vectorizer...\n",
      "TFIDF matrix: (2365, 3570)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       1.00      0.02      0.04        47\n",
      "    negative       0.65      0.45      0.53       178\n",
      "     neutral       0.76      0.16      0.26       100\n",
      "    positive       0.69      0.96      0.81       464\n",
      "\n",
      "    accuracy                           0.69       789\n",
      "   macro avg       0.78      0.40      0.41       789\n",
      "weighted avg       0.71      0.69      0.63       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_sent_tfidf = sentiment.ml(feature_mode=\"TFIDF\", model=LogisticRegression, max_iter=200)\n",
    "# preprocess\n",
    "X_train_sent = logreg_sent_tfidf.preprocess(X_TRAIN_sent.values)\n",
    "X_dev_sent = logreg_sent_tfidf.preprocess(X_DEV_sent.values)\n",
    "\n",
    "# train\n",
    "logreg_sent_tfidf.fit(X_train_sent, Y_TRAIN_sent)\n",
    "\n",
    "# inference\n",
    "y_pred = logreg_sent_tfidf.predict(X_dev_sent)\n",
    "utils.get_reports(y_true = Y_DEV_sent, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b8bb6b",
   "metadata": {},
   "source": [
    "## 1.4) Bidirectional GRU (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ef29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_params = dict(\n",
    "    rnn_layers=[128], \n",
    "    dense_layers=[64], \n",
    "    embedding_matrix=embedding_matrix, \n",
    "    n_outputs=len(Y_TRAIN_sent.unique()), \n",
    "    embedding_trainable=False\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "compile_info = dict(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ade884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_sent = sentiment.dl_pretrained(vocab, compile_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60d6af70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained word embedding\n"
     ]
    }
   ],
   "source": [
    "## Reinstantiate model\n",
    "rnn_sent.set_model_template(get_rnn(**rnn_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0fa61bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Build new LabelEncoder\n"
     ]
    }
   ],
   "source": [
    "X_train_sent, Y_train_sent = rnn_sent.preprocess(X_TRAIN_sent.values, Y_TRAIN_sent.values)\n",
    "X_dev_sent, Y_dev_sent = rnn_sent.preprocess(X_DEV_sent.values, Y_DEV_sent.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35454c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['conflict', 'negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_sent.le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcff1175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "37/37 [==============================] - 14s 223ms/step - loss: 1.4558 - accuracy: 0.4977 - val_loss: 1.1163 - val_accuracy: 0.5881\n",
      "Epoch 2/6\n",
      "37/37 [==============================] - 7s 184ms/step - loss: 1.0806 - accuracy: 0.5822 - val_loss: 1.0657 - val_accuracy: 0.5881\n",
      "Epoch 3/6\n",
      "37/37 [==============================] - 7s 189ms/step - loss: 1.0172 - accuracy: 0.5941 - val_loss: 1.0529 - val_accuracy: 0.5881\n",
      "Epoch 4/6\n",
      "37/37 [==============================] - 7s 186ms/step - loss: 0.9727 - accuracy: 0.5975 - val_loss: 1.0218 - val_accuracy: 0.5881\n",
      "Epoch 5/6\n",
      "37/37 [==============================] - 7s 186ms/step - loss: 0.9772 - accuracy: 0.6051 - val_loss: 1.1142 - val_accuracy: 0.5881\n",
      "Epoch 6/6\n",
      "37/37 [==============================] - 7s 189ms/step - loss: 0.9438 - accuracy: 0.6127 - val_loss: 1.0724 - val_accuracy: 0.5653\n"
     ]
    }
   ],
   "source": [
    "history_rnn_sent = rnn_sent.fit(\n",
    "    X_train_sent, Y_train_sent, X_dev_sent, Y_dev_sent,\n",
    "    batch_size = 64, epochs = 6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09b0f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        47\n",
      "    negative       0.35      0.44      0.39       178\n",
      "     neutral       0.00      0.00      0.00       100\n",
      "    positive       0.65      0.79      0.71       464\n",
      "\n",
      "    accuracy                           0.57       789\n",
      "   macro avg       0.25      0.31      0.28       789\n",
      "weighted avg       0.46      0.57      0.51       789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = rnn_sent.predict(X_dev_sent)\n",
    "utils.get_reports(\n",
    "    y_true = [rnn_sent.le.classes_[i] for i in Y_dev_sent], \n",
    "    y_pred= [rnn_sent.le.classes_[i] for i in y_pred]\n",
    ") # trainable embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edd2a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        23\n",
      "    negative       0.70      0.16      0.26        99\n",
      "     neutral       0.50      0.02      0.03        59\n",
      "    positive       0.61      0.99      0.75       248\n",
      "\n",
      "    accuracy                           0.61       429\n",
      "   macro avg       0.45      0.29      0.26       429\n",
      "weighted avg       0.58      0.61      0.50       429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = rnn_sent.predict(X_dev_sent)\n",
    "utils.get_reports(\n",
    "    y_true = [rnn_sent.le.classes_[i] for i in Y_dev_sent], \n",
    "    y_pred= [rnn_sent.le.classes_[i] for i in y_pred]\n",
    ") #100d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e15323fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_le = rnn_sent.le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4044f51c",
   "metadata": {},
   "source": [
    "## 1.5) CNN (glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ff9a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_params = dict(\n",
    "    n_filters = 16,\n",
    "    kernel_size = 4,\n",
    "    n_cnn_layers = 3,\n",
    "    dense_layers = [64],\n",
    "    embedding_matrix = embedding_matrix,\n",
    "    n_outputs = len(Y_TRAIN_sent.unique()),\n",
    "    embedding_trainable=False\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "compile_info = dict(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5927ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sent = sentiment.dl_pretrained(vocab, compile_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "363c037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained word embedding\n"
     ]
    }
   ],
   "source": [
    "cnn_sent.set_model_template(get_cnn(**cnn_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9517498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Build new LabelEncoder\n"
     ]
    }
   ],
   "source": [
    "#X_train_sent, Y_train_sent = cnn_sent.preprocess(X_TRAIN_sent.values, Y_TRAIN_sent.values, maxlen=maxlen)\n",
    "#X_dev_sent, Y_dev_sent = cnn_sent.preprocess(X_DEV_sent.values, Y_DEV_sent.values, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fba4138f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 1.1462 - accuracy: 0.5581 - val_loss: 1.0994 - val_accuracy: 0.5881\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 1.0799 - accuracy: 0.5920 - val_loss: 1.1241 - val_accuracy: 0.5881\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 1.0604 - accuracy: 0.5949 - val_loss: 1.1289 - val_accuracy: 0.5881\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 1.0637 - accuracy: 0.5941 - val_loss: 1.1290 - val_accuracy: 0.5881\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 1.0561 - accuracy: 0.5962 - val_loss: 1.1666 - val_accuracy: 0.5881\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 1.0556 - accuracy: 0.5962 - val_loss: 1.1626 - val_accuracy: 0.5881\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 1.0518 - accuracy: 0.5962 - val_loss: 1.1306 - val_accuracy: 0.5881\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 1.0517 - accuracy: 0.5970 - val_loss: 1.1234 - val_accuracy: 0.5881\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 1.0448 - accuracy: 0.5949 - val_loss: 1.1168 - val_accuracy: 0.5881\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 1.0416 - accuracy: 0.5958 - val_loss: 1.1129 - val_accuracy: 0.5881\n"
     ]
    }
   ],
   "source": [
    "history_cnn_sent = cnn_sent.fit(\n",
    "    X_train_sent, Y_train_sent, X_dev_sent, Y_dev_sent,\n",
    "    batch_size = 32, epochs = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "957449de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        47\n",
      "    negative       0.00      0.00      0.00       178\n",
      "     neutral       0.00      0.00      0.00       100\n",
      "    positive       0.59      1.00      0.74       464\n",
      "\n",
      "    accuracy                           0.59       789\n",
      "   macro avg       0.15      0.25      0.19       789\n",
      "weighted avg       0.35      0.59      0.44       789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn_sent.predict(X_dev_sent)\n",
    "utils.get_reports(\n",
    "    y_true = [global_le.classes_[i] for i in Y_dev_sent], \n",
    "    y_pred= [global_le.classes_[i] for i in y_pred]\n",
    ") # trainable embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e6766b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        30\n",
      "    negative       0.37      0.41      0.39       120\n",
      "     neutral       0.00      0.00      0.00        71\n",
      "    positive       0.66      0.85      0.74       296\n",
      "\n",
      "    accuracy                           0.58       517\n",
      "   macro avg       0.26      0.31      0.28       517\n",
      "weighted avg       0.46      0.58      0.51       517\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn_sent.predict(X_dev_sent)\n",
    "utils.get_reports(\n",
    "    y_true = [global_le.classes_[i] for i in Y_dev_sent], \n",
    "    y_pred= [global_le.classes_[i] for i in y_pred]\n",
    ") #non-trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8eed46",
   "metadata": {},
   "source": [
    "## 1.6) BOW NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daef4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_bowNN(dense_layers):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for units in dense_layers:\n",
    "        model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(len(Y_TRAIN_sent.unique()), activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "compile_info = dict(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a545042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_nn = sentiment.dl(compile_info, is_bow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5c2d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_nn.set_model_template(get_bowNN([1000,128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbff49a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Adapting new Tokenizer\n",
      "...Build new LabelEncoder\n"
     ]
    }
   ],
   "source": [
    "X_train_sent_bow,Y_train_sent_bow = bow_nn.preprocess(X_TRAIN_sent.values, Y_TRAIN_sent.values, maxtokens=5000)\n",
    "X_dev_sent_bow,Y_dev_sent_bow = bow_nn.preprocess(X_DEV_sent.values, Y_DEV_sent.values, maxtokens=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62f29067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 1.0301 - accuracy: 0.6038 - val_loss: 0.8856 - val_accuracy: 0.6641\n",
      "Epoch 2/7\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.6954 - accuracy: 0.7328 - val_loss: 0.8688 - val_accuracy: 0.6553\n",
      "Epoch 3/7\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.5012 - accuracy: 0.8135 - val_loss: 0.9383 - val_accuracy: 0.6806\n",
      "Epoch 4/7\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.4265 - accuracy: 0.8579 - val_loss: 1.1789 - val_accuracy: 0.6933\n",
      "Epoch 5/7\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 0.4270 - accuracy: 0.8778 - val_loss: 1.0839 - val_accuracy: 0.6679\n",
      "Epoch 6/7\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.3613 - accuracy: 0.8951 - val_loss: 1.3760 - val_accuracy: 0.6895\n",
      "Epoch 7/7\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.3934 - accuracy: 0.9002 - val_loss: 1.4469 - val_accuracy: 0.6755\n"
     ]
    }
   ],
   "source": [
    "history = bow_nn.fit(\n",
    "    X_train_sent_bow, Y_train_sent_bow, X_dev_sent_bow, Y_dev_sent_bow,\n",
    "    batch_size = 32, epochs = 7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9d591d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.33      0.15      0.21        47\n",
      "    negative       0.61      0.46      0.52       178\n",
      "     neutral       0.39      0.41      0.40       100\n",
      "    positive       0.76      0.87      0.81       464\n",
      "\n",
      "    accuracy                           0.68       789\n",
      "   macro avg       0.52      0.47      0.49       789\n",
      "weighted avg       0.66      0.68      0.66       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bow_nn.predict(X_dev_sent_bow)\n",
    "utils.get_reports(\n",
    "    y_true = [bow_nn.le.classes_[i] for i in Y_dev_sent_bow], \n",
    "    y_pred= [bow_nn.le.classes_[i] for i in y_pred]\n",
    ") #non-trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdf22d",
   "metadata": {},
   "source": [
    "# $\\text{2. Aspect}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "395e41bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food' 'price' 'ambience' 'service' 'anecdotes/miscellaneous']\n",
      "['price' 'food' 'ambience' 'service' 'anecdotes/miscellaneous']\n"
     ]
    }
   ],
   "source": [
    "def prep_aspect_df(df_aspect):\n",
    "    temp_df = pd.pivot_table(\n",
    "                    df_aspect,\n",
    "                    index='text',\n",
    "                    values='aspectCategory',\n",
    "                    aggfunc=lambda x: list(x)\n",
    "                )\n",
    "\n",
    "    aspects = df_aspect.aspectCategory.unique()\n",
    "    print(aspects)\n",
    "\n",
    "    for a in aspects:\n",
    "        temp_df[a] = temp_df.apply(lambda x: 1 if a in x.aspectCategory else 0, axis=1)\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "TRAIN_aspect = prep_aspect_df(TRAIN)\n",
    "DEV_aspect = prep_aspect_df(DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15363522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_asp, X_DEV_asp, Y_TRAIN_asp, Y_DEV_asp = TRAIN_aspect.index, DEV_aspect.index, TRAIN_aspect.iloc[:,-5:], DEV_aspect.iloc[:,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d195712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new TFIDF vectorizer...\n",
      "TFIDF matrix: (2034, 3570)\n",
      "Creating new models\n",
      "predicting food...\n",
      "predicting price...\n",
      "predicting ambience...\n",
      "predicting service...\n",
      "predicting anecdotes/miscellaneous...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.16        71\n",
      "           1       0.62      0.83      0.71       261\n",
      "           2       0.54      0.16      0.24        96\n",
      "           3       0.60      0.43      0.50       134\n",
      "           4       0.64      0.85      0.73       227\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       789\n",
      "   macro avg       0.58      0.47      0.47       789\n",
      "weighted avg       0.60      0.62      0.57       789\n",
      " samples avg       0.63      0.63      0.62       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from my_models import aspect\n",
    "\n",
    "logreg_asp_bow = aspect.ml(feature_mode=\"TFIDF\", model=LogisticRegression)\n",
    "# preprocess\n",
    "X_train_asp = logreg_asp_bow.preprocess(X_TRAIN_asp, Y_TRAIN_asp)\n",
    "X_dev_asp = logreg_asp_bow.preprocess(X_DEV_asp, Y_DEV_asp)\n",
    "\n",
    "logreg_asp_bow.fit(X_train_asp, Y_TRAIN_asp)\n",
    "\n",
    "outputs, outputs_prob = logreg_asp_bow.predict(X_dev_asp)\n",
    "\n",
    "def swapCol(true_df, pred_df):    \n",
    "    return pd.DataFrame(\n",
    "        {y_true_col: pred_df[y_true_col] for y_true_col in true_df.columns}\n",
    "    )\n",
    "outputs = swapCol(Y_DEV_asp, outputs)\n",
    "    \n",
    "utils.get_reports(\n",
    "    y_true = Y_DEV_asp.reset_index(drop=True), \n",
    "    y_pred= outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62d2cd",
   "metadata": {},
   "source": [
    "## 2.1) Logistic regression (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd632e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new models\n",
      "Creating new BOW vectorizer...\n",
      "BOW matrix: (2065, 3633)\n",
      "predicting service...\n",
      "predicting food...\n",
      "predicting anecdotes/miscellaneous...\n",
      "predicting price...\n",
      "predicting ambience...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78       106\n",
      "           1       0.88      0.79      0.84       209\n",
      "           2       0.77      0.74      0.76       191\n",
      "           3       0.88      0.54      0.67        56\n",
      "           4       0.91      0.44      0.59        73\n",
      "\n",
      "   micro avg       0.85      0.70      0.76       635\n",
      "   macro avg       0.87      0.64      0.73       635\n",
      "weighted avg       0.86      0.70      0.76       635\n",
      " samples avg       0.72      0.70      0.70       635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from my_models import aspect\n",
    "\n",
    "logreg_aspect_bow = aspect.LOGREG(feature_mode='BOW')\n",
    "X_train_asp = logreg_aspect_bow.preprocess(X_TRAIN_asp, Y_TRAIN_asp)\n",
    "X_dev_asp = logreg_aspect_bow.preprocess(X_DEV_asp, Y_DEV_asp)\n",
    "\n",
    "logreg_aspect_bow.fit(X_train_asp, Y_TRAIN_asp)\n",
    "\n",
    "outputs = logreg_aspect_bow.predict(X_dev_asp)\n",
    "\n",
    "utils.get_reports(\n",
    "    y_true = Y_DEV_asp.values, \n",
    "    y_pred= outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef953b2",
   "metadata": {},
   "source": [
    "## 2.2) Logistic regerssion (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "828a0dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new models\n",
      "Creating new TFIDF vectorizer...\n",
      "TFIDF matrix: (2065, 3633)\n",
      "predicting service...\n",
      "predicting food...\n",
      "predicting anecdotes/miscellaneous...\n",
      "predicting price...\n",
      "predicting ambience...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65       106\n",
      "           1       0.91      0.72      0.80       209\n",
      "           2       0.83      0.59      0.69       191\n",
      "           3       0.89      0.14      0.25        56\n",
      "           4       0.89      0.11      0.20        73\n",
      "\n",
      "   micro avg       0.89      0.52      0.66       635\n",
      "   macro avg       0.90      0.41      0.52       635\n",
      "weighted avg       0.90      0.52      0.62       635\n",
      " samples avg       0.59      0.55      0.56       635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from my_models import aspect\n",
    "\n",
    "logreg_aspect_tfidf = aspect.LOGREG(feature_mode='TFIDF')\n",
    "X_train_asp = logreg_aspect_tfidf.preprocess(X_TRAIN_asp, Y_TRAIN_asp)\n",
    "X_dev_asp = logreg_aspect_tfidf.preprocess(X_DEV_asp, Y_DEV_asp)\n",
    "\n",
    "logreg_aspect_tfidf.fit(X_train_asp, Y_TRAIN_asp)\n",
    "\n",
    "outputs = logreg_aspect_tfidf.predict(X_dev_asp)\n",
    "\n",
    "utils.get_reports(\n",
    "    y_true = Y_DEV_asp.values, \n",
    "    y_pred= outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8adf12",
   "metadata": {},
   "source": [
    "## 2.3) Bidirectional GRU (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d871631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['service', 'food', 'anecdotes/miscellaneous', 'price', 'ambience'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_TRAIN_asp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72f52440",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_params = dict(\n",
    "    rnn_layers=[128,128], \n",
    "    dense_layers=[64,64], \n",
    "    embedding_matrix=embedding_matrix, \n",
    "    n_outputs=1, \n",
    "    embedding_trainable=False\n",
    ")\n",
    "compile_info = dict(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8760c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_models import aspect\n",
    "rnn_asp = aspect.dl_pretrained(vocab, compile_info, n_models=len(Y_TRAIN_asp.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3e03b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained word embedding\n"
     ]
    }
   ],
   "source": [
    "from my_models.inference import get_rnn\n",
    "# Reinstantiate models\n",
    "rnn_asp.set_model_template(get_rnn(**rnn_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59192f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_asp, Y_train_asp = rnn_asp.preprocess(X_TRAIN_asp, Y_TRAIN_asp, maxtokens = embedding_matrix.shape[0], maxlen=30)\n",
    "X_dev_asp, Y_dev_asp = rnn_asp.preprocess(X_DEV_asp, Y_DEV_asp, maxtokens = embedding_matrix.shape[0], maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49dac7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting food ...\n",
      "\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 35s 341ms/step - loss: 0.8144 - accuracy: 0.5521 - val_loss: 0.6685 - val_accuracy: 0.6312\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 18s 274ms/step - loss: 0.7294 - accuracy: 0.5836 - val_loss: 0.6601 - val_accuracy: 0.6671\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 16s 253ms/step - loss: 0.6871 - accuracy: 0.6224 - val_loss: 0.5982 - val_accuracy: 0.6711\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 17s 263ms/step - loss: 0.6458 - accuracy: 0.6441 - val_loss: 0.5811 - val_accuracy: 0.7177\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 17s 265ms/step - loss: 0.6155 - accuracy: 0.6799 - val_loss: 0.5680 - val_accuracy: 0.7044\n",
      "fitting price ...\n",
      "\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 40s 353ms/step - loss: 0.4754 - accuracy: 0.8289 - val_loss: 0.4212 - val_accuracy: 0.9055\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 16s 255ms/step - loss: 0.4331 - accuracy: 0.8707 - val_loss: 0.3692 - val_accuracy: 0.9055\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 17s 265ms/step - loss: 0.3838 - accuracy: 0.8859 - val_loss: 0.3742 - val_accuracy: 0.9055\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 18s 281ms/step - loss: 0.3615 - accuracy: 0.8889 - val_loss: 0.3441 - val_accuracy: 0.9055\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 18s 277ms/step - loss: 0.3464 - accuracy: 0.8928 - val_loss: 0.3333 - val_accuracy: 0.9055\n",
      "fitting ambience ...\n",
      "\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 44s 421ms/step - loss: 0.5510 - accuracy: 0.7852 - val_loss: 0.5343 - val_accuracy: 0.8722\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 19s 298ms/step - loss: 0.4529 - accuracy: 0.8382 - val_loss: 0.4766 - val_accuracy: 0.8722\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 19s 296ms/step - loss: 0.4641 - accuracy: 0.8500 - val_loss: 0.4276 - val_accuracy: 0.8722\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 19s 296ms/step - loss: 0.4245 - accuracy: 0.8555 - val_loss: 0.3828 - val_accuracy: 0.8722\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 20s 307ms/step - loss: 0.4055 - accuracy: 0.8618 - val_loss: 0.4439 - val_accuracy: 0.8722\n",
      "fitting service ...\n",
      "\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 51s 422ms/step - loss: 0.6230 - accuracy: 0.7217 - val_loss: 0.6343 - val_accuracy: 0.8216\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 19s 301ms/step - loss: 0.5245 - accuracy: 0.7842 - val_loss: 0.5561 - val_accuracy: 0.8216\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 21s 323ms/step - loss: 0.4943 - accuracy: 0.7984 - val_loss: 0.5362 - val_accuracy: 0.8229\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 20s 308ms/step - loss: 0.4876 - accuracy: 0.8038 - val_loss: 0.5419 - val_accuracy: 0.8256\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 20s 312ms/step - loss: 0.4521 - accuracy: 0.8176 - val_loss: 0.4498 - val_accuracy: 0.8309\n",
      "fitting anecdotes/miscellaneous ...\n",
      "\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 47s 396ms/step - loss: 0.8159 - accuracy: 0.5723 - val_loss: 0.6301 - val_accuracy: 0.7044\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 19s 302ms/step - loss: 0.6979 - accuracy: 0.6254 - val_loss: 0.5517 - val_accuracy: 0.7084\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 19s 295ms/step - loss: 0.6337 - accuracy: 0.6519 - val_loss: 0.5599 - val_accuracy: 0.7324\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 20s 307ms/step - loss: 0.6097 - accuracy: 0.6721 - val_loss: 0.4980 - val_accuracy: 0.7577\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 20s 316ms/step - loss: 0.5997 - accuracy: 0.6903 - val_loss: 0.5889 - val_accuracy: 0.7390\n"
     ]
    }
   ],
   "source": [
    "histories = rnn_asp.fit(\n",
    "                X_train_asp, Y_train_asp, X_dev_asp, Y_dev_asp,\n",
    "                batch_size = 32, epochs = 5\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b1826b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "        outputs_prob = []\n",
    "        threshold = 0.5\n",
    "        for aspect, model in zip(rnn_asp.classes, rnn_asp.models):\n",
    "            print(f'predicting {aspect}...')\n",
    "            y_pred_target = model.predict(X)\n",
    "            #y_pred = tf.cast(y_pred_target > threshold, tf.int32) \n",
    "            outputs_prob.append(y_pred_target.ravel())\n",
    "            \n",
    "        outputs_prob = np.transpose(np.array(outputs_prob))        \n",
    "        \n",
    "        outputs = []\n",
    "        for row in outputs_prob:\n",
    "            pred = np.where(row > threshold, 1, 0)\n",
    "            if np.sum(pred) > 0:\n",
    "                outputs.append(pred)\n",
    "            else:\n",
    "                zeros = np.zeros_like(pred)\n",
    "                zeros[np.argmax(row)] = 1\n",
    "                outputs.append(zeros)\n",
    "        \n",
    "        outputs_df = pd.DataFrame(np.array(outputs), columns=rnn_asp.classes)\n",
    "        outputs_prob = pd.DataFrame(np.array(outputs_prob), columns=rnn_asp.classes)\n",
    "\n",
    "        return outputs_df, outputs_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7b710b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting food...\n",
      "predicting price...\n",
      "predicting ambience...\n",
      "predicting service...\n",
      "predicting anecdotes/miscellaneous...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.10      0.14        71\n",
      "           1       0.61      0.52      0.57       261\n",
      "           2       0.20      0.23      0.21        96\n",
      "           3       0.30      0.62      0.41       134\n",
      "           4       0.71      0.37      0.49       227\n",
      "\n",
      "   micro avg       0.44      0.42      0.43       789\n",
      "   macro avg       0.42      0.37      0.36       789\n",
      "weighted avg       0.51      0.42      0.44       789\n",
      " samples avg       0.44      0.43      0.43       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs, _ = predict(X_dev_asp)\n",
    "\n",
    "outputs_df = swapCol(Y_dev_asp, outputs)\n",
    "\n",
    "utils.get_reports(\n",
    "    y_true = Y_dev_asp.values, \n",
    "    y_pred= outputs_df\n",
    ") #non-trainable 300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14ae0b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting service...\n",
      "predicting food...\n",
      "predicting anecdotes/miscellaneous...\n",
      "predicting price...\n",
      "predicting ambience...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75       106\n",
      "           1       0.70      0.80      0.75       209\n",
      "           2       0.69      0.76      0.72       191\n",
      "           3       0.75      0.48      0.59        56\n",
      "           4       0.45      0.32      0.37        73\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       635\n",
      "   macro avg       0.68      0.61      0.64       635\n",
      "weighted avg       0.69      0.69      0.68       635\n",
      " samples avg       0.67      0.70      0.66       635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "outputs = rnn_asp.predict(X_dev_asp)\n",
    "\n",
    "outputs = swapCol(Y_dev_asp, outputs)\n",
    "\n",
    "utils.get_reports(\n",
    "    y_true = Y_dev_asp.values, \n",
    "    y_pred= outputs\n",
    ") #non-trainable 300d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8be002",
   "metadata": {},
   "source": [
    "## 2.4) CNN (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71ea74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_params = dict(\n",
    "    n_filters = 64,\n",
    "    kernel_size = 3,\n",
    "    n_cnn_layers = 3,\n",
    "    dense_layers = [64,64],\n",
    "    embedding_matrix = embedding_matrix,\n",
    "    n_outputs = 1,\n",
    "    embedding_trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ba9cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_asp = aspect.dl_glove(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77a99fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained word embedding\n",
      "cloning model from template...\n"
     ]
    }
   ],
   "source": [
    "# Reinstantiate models\n",
    "cnn_asp.set_model_template(get_cnn(**cnn_params), n_models = len(Y_TRAIN_asp.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddc60419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting service ...\n",
      "\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 4s 19ms/step - loss: 0.5369 - accuracy: 0.7995 - val_loss: 0.4988 - val_accuracy: 0.7950\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 1s 13ms/step - loss: 0.4774 - accuracy: 0.8063 - val_loss: 0.4615 - val_accuracy: 0.7950\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 0.3765 - accuracy: 0.8286 - val_loss: 0.3308 - val_accuracy: 0.8781\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.2190 - accuracy: 0.9230 - val_loss: 0.2930 - val_accuracy: 0.8917\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.1061 - accuracy: 0.9714 - val_loss: 0.3829 - val_accuracy: 0.8936\n",
      "fitting food ...\n",
      "\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 4s 19ms/step - loss: 0.6731 - accuracy: 0.5821 - val_loss: 0.6228 - val_accuracy: 0.6983\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.5508 - accuracy: 0.7317 - val_loss: 0.5280 - val_accuracy: 0.7389\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.4237 - accuracy: 0.8213 - val_loss: 0.4703 - val_accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.2970 - accuracy: 0.8862 - val_loss: 0.4520 - val_accuracy: 0.8124\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 0.1724 - accuracy: 0.9438 - val_loss: 0.7247 - val_accuracy: 0.7930\n",
      "fitting anecdotes/miscellaneous ...\n",
      "\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 2s 20ms/step - loss: 0.6454 - accuracy: 0.6242 - val_loss: 0.6072 - val_accuracy: 0.6306\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.5743 - accuracy: 0.6969 - val_loss: 0.5041 - val_accuracy: 0.7466\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.4422 - accuracy: 0.8019 - val_loss: 0.4640 - val_accuracy: 0.7872\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 0.3264 - accuracy: 0.8673 - val_loss: 0.5635 - val_accuracy: 0.7602\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.2200 - accuracy: 0.9172 - val_loss: 0.6026 - val_accuracy: 0.7795\n",
      "fitting price ...\n",
      "\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 2s 20ms/step - loss: 0.3951 - accuracy: 0.8896 - val_loss: 0.3382 - val_accuracy: 0.8917\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 0.3391 - accuracy: 0.8939 - val_loss: 0.3277 - val_accuracy: 0.8917\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 1s 21ms/step - loss: 0.2946 - accuracy: 0.8939 - val_loss: 0.3392 - val_accuracy: 0.8917\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.2236 - accuracy: 0.9007 - val_loss: 0.3045 - val_accuracy: 0.8936\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.1469 - accuracy: 0.9366 - val_loss: 0.4411 - val_accuracy: 0.9072\n",
      "fitting ambience ...\n",
      "\n",
      "Epoch 1/5\n",
      "65/65 [==============================] - 3s 27ms/step - loss: 0.4522 - accuracy: 0.8542 - val_loss: 0.4121 - val_accuracy: 0.8588\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 0.4031 - accuracy: 0.8571 - val_loss: 0.4132 - val_accuracy: 0.8588\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.3748 - accuracy: 0.8571 - val_loss: 0.4058 - val_accuracy: 0.8588\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 0.2975 - accuracy: 0.8649 - val_loss: 0.4166 - val_accuracy: 0.8530\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.2211 - accuracy: 0.8978 - val_loss: 0.6378 - val_accuracy: 0.8569\n"
     ]
    }
   ],
   "source": [
    "histories = cnn_asp.fit(\n",
    "                X_train_asp, Y_train_asp, X_dev_asp, Y_dev_asp,\n",
    "                batch_size = 32, epochs = 5\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13063499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting service...\n",
      "predicting food...\n",
      "predicting anecdotes/miscellaneous...\n",
      "predicting price...\n",
      "predicting ambience...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.58      0.69       106\n",
      "           1       0.87      0.57      0.69       209\n",
      "           2       0.72      0.67      0.69       191\n",
      "           3       0.83      0.18      0.29        56\n",
      "           4       0.44      0.05      0.10        73\n",
      "\n",
      "   micro avg       0.79      0.51      0.62       635\n",
      "   macro avg       0.74      0.41      0.49       635\n",
      "weighted avg       0.77      0.51      0.59       635\n",
      " samples avg       0.56      0.53      0.54       635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsa\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def manual_predict(X, threshold=0.5):\n",
    "    outputs = []\n",
    "    threshold = 0.5\n",
    "    for aspect, model in zip(Y_train_asp.columns, cnn_asp.models):\n",
    "        print(f'predicting {aspect}...')\n",
    "        y_pred_target = model.predict(X)\n",
    "        y_pred = tf.cast(y_pred_target > threshold, tf.int32) \n",
    "        outputs.append(y_pred.numpy().ravel())\n",
    "\n",
    "    outputs = np.transpose(np.array(outputs))\n",
    "    return outputs\n",
    "\n",
    "outputs = manual_predict(X_dev_asp)\n",
    "utils.get_reports(\n",
    "    y_true = Y_dev_asp.values, \n",
    "    y_pred= outputs\n",
    ") #non-trainable 300d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7729dfb",
   "metadata": {},
   "source": [
    "# $\\text{Inference}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9d4128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from my_models import inference\n",
    "\n",
    "sent_names = ['logreg_sent_bow','logreg_sent_tfidf','rnn_sent','cnn_sent']\n",
    "asp_names = ['logreg_aspect','rnn_asp']\n",
    "model_names = itertools.product(sent_names, asp_names)\n",
    "\n",
    "sent_models = [\n",
    "    logreg_sent_bow,\n",
    "    logreg_sent_tfidf,\n",
    "    rnn_sent,\n",
    "    cnn_sent\n",
    "]\n",
    "\n",
    "asp_models = [\n",
    "    logreg_aspect,\n",
    "    rnn_asp\n",
    "]\n",
    "models = itertools.product(sent_models, asp_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "33f1088e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('logreg_sent_bow', 'logreg_aspect')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MulBinary_logreg.preprocess() got an unexpected keyword argument 'vocab_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[0;32m      6\u001b[0m inferencer \u001b[38;5;241m=\u001b[39m inference\u001b[38;5;241m.\u001b[39mInferenceModel(\u001b[38;5;241m*\u001b[39mmodel)\n\u001b[1;32m----> 7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43minferencer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_inference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m outputs\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting_predictions/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_train-set.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\my_models\\inference.py:11\u001b[0m, in \u001b[0;36mInferenceModel.predict\u001b[1;34m(self, X_raw)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_raw:pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m     10\u001b[0m     X_sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentiment_model\u001b[38;5;241m.\u001b[39mpreprocess(X_raw\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m---> 11\u001b[0m     X_asp  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maspect_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     sent_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentiment_model\u001b[38;5;241m.\u001b[39mpredict(X_sent)\n\u001b[0;32m     14\u001b[0m     asp_pred  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maspect_model\u001b[38;5;241m.\u001b[39mpredict(X_asp)\n",
      "\u001b[1;31mTypeError\u001b[0m: MulBinary_logreg.preprocess() got an unexpected keyword argument 'vocab_size'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"contest1_train.csv\")\n",
    "df_train_inference = df_train[['id','text']]\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    print(name)\n",
    "    inferencer = inference.InferenceModel(*model)\n",
    "    outputs = inferencer.predict(df_train_inference)\n",
    "\n",
    "    outputs.to_csv(f\"resulting_predictions/{name[0]}_{name[1]}_train-set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a5322f",
   "metadata": {},
   "source": [
    "## TRAIN set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdba5d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting service...\n",
      "predicting food...\n",
      "predicting anecdotes/miscellaneous...\n",
      "predicting price...\n",
      "predicting ambience...\n"
     ]
    }
   ],
   "source": [
    "from my_models import inference\n",
    "\n",
    "inferencer = inference.InferenceModel(logreg_sent_bow, logreg_asp_bow)\n",
    "\n",
    "df_train = pd.read_csv(\"contest1_train.csv\")\n",
    "\n",
    "df_train_inference = df_train[['id','text']]\n",
    "outputs = inferencer.predict(df_train_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c064f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = \"resulting_predictions/\"\n",
    "outputs.to_csv(path_to_save + \"train-pred-2-bow-rnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a88bf8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df_train['aspectCategory']+'-'+df_train['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97d1f375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       service-negative\n",
       "1                          food-positive\n",
       "2       anecdotes/miscellaneous-negative\n",
       "3                          food-positive\n",
       "4                       service-positive\n",
       "                      ...               \n",
       "3151    anecdotes/miscellaneous-positive\n",
       "3152                    service-positive\n",
       "3153    anecdotes/miscellaneous-positive\n",
       "3154                       food-positive\n",
       "3155                        food-neutral\n",
       "Length: 3156, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8a1e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = outputs[1]['aspectCategory']+'-'+outputs[1]['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23e056ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3156, 4261]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m----> 4\u001b[0m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2110\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   1998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[0;32m   1999\u001b[0m     y_true,\n\u001b[0;32m   2000\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2007\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2008\u001b[0m ):\n\u001b[0;32m   2009\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2010\u001b[0m \n\u001b[0;32m   2011\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2110\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2113\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n",
      "File \u001b[1;32m~\\Downloads\\University-Chula\\Y4-2\\Contest 1 Sentiment Analysis\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3156, 4261]"
     ]
    }
   ],
   "source": [
    "outputs[1]\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_report(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f969fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[1].to_csv(\"resulting_predictions/sunday_train_bow_bow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
