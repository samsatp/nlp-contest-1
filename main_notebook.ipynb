{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e6efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from my_models.inference import get_rnn, get_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012c90f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('price', 'food', 'ambience', 'service', 'anecdotes/miscellaneous')\n"
     ]
    }
   ],
   "source": [
    "TRAIN = pd.read_csv(\"TRAIN.csv\")\n",
    "DEV = pd.read_csv(\"DEV.csv\")\n",
    "\n",
    "aspect_order = tuple(DEV.aspectCategory.unique())\n",
    "print(aspect_order)\n",
    "\n",
    "df_aspect = TRAIN[['id','text', 'aspectCategory']]\n",
    "df_sentiment = TRAIN[['id','text', 'polarity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3ad02",
   "metadata": {},
   "source": [
    "# Read embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f7ef461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_models import utils\n",
    "\n",
    "emb_dim = 100\n",
    "vocab, embedding_matrix = utils.get_embeddings(emb_dim)\n",
    "\n",
    "maxlen = 30\n",
    "vocab_size = embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54132245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dups(df):\n",
    "    if any(df.duplicated()):\n",
    "        dups = df[df.duplicated()]\n",
    "        return df.drop_duplicates()\n",
    "    \n",
    "df_aspect = drop_dups(df_aspect)\n",
    "df_sentiment = drop_dups(df_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72f2e3",
   "metadata": {},
   "source": [
    "# 0) Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e68b10",
   "metadata": {},
   "source": [
    "# 1) Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2d54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_models import sentiment\n",
    "\n",
    "X_TRAIN_sent, X_DEV_sent, Y_TRAIN_sent, Y_DEV_sent = TRAIN['text'], DEV['text'], TRAIN['polarity'], DEV['polarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eab3d0",
   "metadata": {},
   "source": [
    "## 1.1) Log reg - bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a3a19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gym_sentiment_ml(\n",
    "    feature_mode, \n",
    "    model, \n",
    "    X_TRAIN_sent=X_TRAIN_sent, X_DEV_sent=X_DEV_sent, \n",
    "    Y_TRAIN_sent=Y_TRAIN_sent, Y_DEV_sent=Y_DEV_sent, \n",
    "    **kwargs\n",
    "):\n",
    "    sent_model = sentiment.ml(feature_mode, model, **kwargs)\n",
    "    \n",
    "    # preprocess\n",
    "    X_train_sent = sent_model.preprocess(X_TRAIN_sent.values)\n",
    "    X_dev_sent   = sent_model.preprocess(X_DEV_sent.values)\n",
    "\n",
    "    # train\n",
    "    sent_model.fit(X_train_sent, Y_TRAIN_sent)\n",
    "\n",
    "    # inference\n",
    "    y_pred = sent_model.predict(X_dev_sent)\n",
    "    utils.get_reports(y_true = Y_DEV_sent, y_pred=y_pred)\n",
    "    return sent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ecc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new BOW vectorizer...\n",
      "BOW matrix: (2365, 3570)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.29      0.13      0.18        47\n",
      "    negative       0.59      0.48      0.53       178\n",
      "     neutral       0.45      0.30      0.36       100\n",
      "    positive       0.75      0.89      0.81       464\n",
      "\n",
      "    accuracy                           0.68       789\n",
      "   macro avg       0.52      0.45      0.47       789\n",
      "weighted avg       0.65      0.68      0.65       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_sent_bow = gym_sentiment_ml(\"BOW\", LogisticRegression, max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7556db",
   "metadata": {},
   "source": [
    "## 1.2) Log reg - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92a4374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new TFIDF vectorizer...\n",
      "TFIDF matrix: (2365, 3570)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       1.00      0.02      0.04        47\n",
      "    negative       0.65      0.45      0.53       178\n",
      "     neutral       0.76      0.16      0.26       100\n",
      "    positive       0.69      0.96      0.81       464\n",
      "\n",
      "    accuracy                           0.69       789\n",
      "   macro avg       0.78      0.40      0.41       789\n",
      "weighted avg       0.71      0.69      0.63       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_sent_bow = gym_sentiment_ml(\"TFIDF\", LogisticRegression, max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79642948",
   "metadata": {},
   "source": [
    "## 1.3) bowNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77b99658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gym_sentiment_dl(\n",
    "    is_bow,\n",
    "    model_template,\n",
    "    compile_info,\n",
    "    epochs = 5,\n",
    "    use_pretrained = True,\n",
    "    X_TRAIN_sent=X_TRAIN_sent, X_DEV_sent=X_DEV_sent, \n",
    "    Y_TRAIN_sent=Y_TRAIN_sent, Y_DEV_sent=Y_DEV_sent, \n",
    "    **kwargs\n",
    "):\n",
    "    if use_pretrained:\n",
    "        print(\"use pretrained emb\")\n",
    "        model = sentiment.dl_pretrained(vocab, compile_info)\n",
    "    else:\n",
    "        model = sentiment.dl(compile_info, is_bow)\n",
    "    model.set_model_template(model_template)\n",
    "    \n",
    "    X_train_sent,Y_train_sent = model.preprocess(X_TRAIN_sent.values, Y_TRAIN_sent.values, **kwargs)\n",
    "    X_dev_sent,Y_dev_sent     = model.preprocess(X_DEV_sent.values, Y_DEV_sent.values, **kwargs)\n",
    "    \n",
    "    history = model.fit(\n",
    "                    X_train_sent, Y_train_sent, X_dev_sent, Y_dev_sent,\n",
    "                    batch_size = 32, epochs = epochs\n",
    "                )\n",
    "    \n",
    "    y_pred = model.predict(X_dev_sent)\n",
    "    utils.get_reports(\n",
    "        y_true = [model.le.classes_[i] for i in Y_dev_sent], \n",
    "        y_pred= [model.le.classes_[i] for i in y_pred]\n",
    "    )\n",
    "    return model, history, (X_train_sent, Y_train_sent), (X_dev_sent, Y_dev_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e5b6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_bowNN(dense_layers):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for units in dense_layers:\n",
    "        model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(len(Y_TRAIN_sent.unique()), activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "compile_info = dict(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d115582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Adapting new Tokenizer\n",
      "...Build new LabelEncoder\n",
      "Epoch 1/5\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 1.0386 - accuracy: 0.5911 - val_loss: 0.9132 - val_accuracy: 0.6274\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.6927 - accuracy: 0.7230 - val_loss: 0.8250 - val_accuracy: 0.7022\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.4271 - accuracy: 0.8465 - val_loss: 0.8918 - val_accuracy: 0.6895\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 2s 20ms/step - loss: 0.2822 - accuracy: 0.9146 - val_loss: 0.9602 - val_accuracy: 0.6958\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.2182 - accuracy: 0.9366 - val_loss: 1.0209 - val_accuracy: 0.7009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.41      0.23      0.30        47\n",
      "    negative       0.63      0.52      0.57       178\n",
      "     neutral       0.44      0.34      0.38       100\n",
      "    positive       0.77      0.90      0.83       464\n",
      "\n",
      "    accuracy                           0.70       789\n",
      "   macro avg       0.56      0.50      0.52       789\n",
      "weighted avg       0.68      0.70      0.68       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bow_nn, bow_nn_hist, train_data_sent, dev_data_sent = gym_sentiment_dl(True, get_bowNN([1000,256]), compile_info, use_pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686bf0a",
   "metadata": {},
   "source": [
    "### 1.3.1) tfidf NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a950338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Adapting new Tokenizer\n",
      "...Build new LabelEncoder\n",
      "Epoch 1/5\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 1.0546 - accuracy: 0.5839 - val_loss: 0.8906 - val_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.5972 - accuracy: 0.7831 - val_loss: 0.9428 - val_accuracy: 0.7034\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.3733 - accuracy: 0.8875 - val_loss: 1.0359 - val_accuracy: 0.6984\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.2627 - accuracy: 0.9260 - val_loss: 1.1312 - val_accuracy: 0.7047\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.2248 - accuracy: 0.9442 - val_loss: 1.2688 - val_accuracy: 0.6907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.41      0.15      0.22        47\n",
      "    negative       0.68      0.49      0.57       178\n",
      "     neutral       0.42      0.30      0.35       100\n",
      "    positive       0.74      0.91      0.81       464\n",
      "\n",
      "    accuracy                           0.69       789\n",
      "   macro avg       0.56      0.46      0.49       789\n",
      "weighted avg       0.66      0.69      0.66       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "compile_info = dict(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "tfidf_nn, tfidf_nn_hist, train_data, dev_data = gym_sentiment_dl('tfidf', get_bowNN([1000,256]), compile_info, use_pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99607c9c",
   "metadata": {},
   "source": [
    "## 1.4) Bidir-GRU (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a7f8d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained word embedding\n",
      "use pretrained emb\n",
      "...Build new LabelEncoder\n",
      "Epoch 1/5\n",
      "74/74 [==============================] - 58s 611ms/step - loss: 1.3717 - accuracy: 0.5268 - val_loss: 1.0726 - val_accuracy: 0.5881\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 41s 556ms/step - loss: 0.9943 - accuracy: 0.6034 - val_loss: 0.9919 - val_accuracy: 0.5995\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 42s 561ms/step - loss: 0.8486 - accuracy: 0.6486 - val_loss: 1.0533 - val_accuracy: 0.5488\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 41s 549ms/step - loss: 0.7261 - accuracy: 0.7125 - val_loss: 1.4412 - val_accuracy: 0.6451\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 42s 562ms/step - loss: 0.6788 - accuracy: 0.7408 - val_loss: 1.0358 - val_accuracy: 0.6286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.50      0.04      0.08        47\n",
      "    negative       0.50      0.46      0.48       178\n",
      "     neutral       0.29      0.39      0.33       100\n",
      "    positive       0.76      0.80      0.78       464\n",
      "\n",
      "    accuracy                           0.63       789\n",
      "   macro avg       0.51      0.42      0.42       789\n",
      "weighted avg       0.63      0.63      0.62       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = maxtokens = 5000\n",
    "\n",
    "rnn_params = dict(\n",
    "    rnn_layers=[128], \n",
    "    dense_layers=[64], \n",
    "    embedding_matrix=embedding_matrix, \n",
    "    n_outputs=len(Y_TRAIN_sent.unique()), \n",
    "    embedding_trainable=True,\n",
    "    #vocab_size = vocab_size,\n",
    "    #emb_dim = 256\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "compile_info = dict(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "bidir_sent, bidir_sent_hist, train_data_sent, dev_data_sent = gym_sentiment_dl(False, get_rnn(**rnn_params), compile_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074f72f1",
   "metadata": {},
   "source": [
    "## 1.5) CNN (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b415cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, GlobalAveragePooling1D\n",
    "def make_cnn_model(n_outputs, embedding_trainable=False):\n",
    "    filters = 250 \n",
    "    kernel_size = 3 \n",
    "    hidden_dims = 250 \n",
    "    vocab_size, emb_dim = embedding_matrix.shape\n",
    "\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(\n",
    "        Embedding(\n",
    "                input_dim=vocab_size,\n",
    "                output_dim=emb_dim, \n",
    "                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                mask_zero=True,\n",
    "                trainable=embedding_trainable\n",
    "                ) \n",
    "    )\n",
    "    \n",
    "    cnn_model.add(Conv1D(filters,\n",
    "                        kernel_size,\n",
    "                        activation='relu',\n",
    "                        strides=1))\n",
    "\n",
    "    cnn_model.add(GlobalAveragePooling1D())\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    cnn_model.add(Dense(hidden_dims, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b13cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use pretrained emb\n",
      "...Build new LabelEncoder\n",
      "Epoch 1/5\n",
      "74/74 [==============================] - 41s 540ms/step - loss: 1.0933 - accuracy: 0.5793 - val_loss: 1.0156 - val_accuracy: 0.5906\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 36s 486ms/step - loss: 0.8841 - accuracy: 0.6592 - val_loss: 0.8708 - val_accuracy: 0.6679\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 37s 504ms/step - loss: 0.7103 - accuracy: 0.7175 - val_loss: 0.9649 - val_accuracy: 0.6717\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 37s 497ms/step - loss: 0.5977 - accuracy: 0.7683 - val_loss: 1.0543 - val_accuracy: 0.6692\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 37s 494ms/step - loss: 0.4891 - accuracy: 0.8131 - val_loss: 0.9926 - val_accuracy: 0.6616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.57      0.09      0.15        47\n",
      "    negative       0.57      0.49      0.53       178\n",
      "     neutral       0.34      0.43      0.38       100\n",
      "    positive       0.77      0.84      0.80       464\n",
      "\n",
      "    accuracy                           0.66       789\n",
      "   macro avg       0.56      0.46      0.46       789\n",
      "weighted avg       0.66      0.66      0.65       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "compile_info = dict(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "n_outputs = len(Y_TRAIN_sent.unique())\n",
    "cnn_sent, cn_sent_hist, train_data_sent, dev_data_sent = gym_sentiment_dl(False, make_cnn_model(n_outputs, embedding_trainable=True), compile_info, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f0b3a",
   "metadata": {},
   "source": [
    "# 2) Aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ba363e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['price', 'food', 'ambience', 'service', 'anecdotes/miscellaneous'], dtype='object')\n",
      "Index(['price', 'food', 'ambience', 'service', 'anecdotes/miscellaneous'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def swapCol(df):    \n",
    "    df = pd.DataFrame(\n",
    "        {aspect: df[aspect] for aspect in aspect_order}\n",
    "    )\n",
    "    assert aspect_order == tuple(df.columns)\n",
    "    return df\n",
    "\n",
    "def prep_aspect_df(df_aspect):\n",
    "    temp_df = pd.pivot_table(\n",
    "                    df_aspect,\n",
    "                    index='text',\n",
    "                    values='aspectCategory',\n",
    "                    aggfunc=lambda x: list(x)\n",
    "                )\n",
    "\n",
    "    for a in aspect_order:\n",
    "        temp_df[a] = temp_df.apply(lambda x: 1 if a in x.aspectCategory else 0, axis=1)\n",
    "\n",
    "    temp_df.drop(['aspectCategory'], axis=1, inplace=True)\n",
    "    print(temp_df.columns)\n",
    "    return temp_df\n",
    "\n",
    "TRAIN_aspect = prep_aspect_df(TRAIN)\n",
    "DEV_aspect = prep_aspect_df(DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb465f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TRAIN_asp, X_DEV_asp, Y_TRAIN_asp, Y_DEV_asp = TRAIN_aspect.index, DEV_aspect.index, TRAIN_aspect, DEV_aspect\n",
    "all(Y_DEV_asp.columns == Y_TRAIN_asp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa910b7",
   "metadata": {},
   "source": [
    "## 2.1) Logreg - bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf9660ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_models import aspect\n",
    "\n",
    "def gym_aspect_ml(\n",
    "    feature_mode, model,\n",
    "    X_TRAIN_sent=X_TRAIN_asp, X_DEV_sent=X_DEV_asp, \n",
    "    Y_TRAIN_sent=Y_TRAIN_asp, Y_DEV_sent=Y_DEV_asp, \n",
    "    **kwargs\n",
    "):\n",
    "    model = aspect.ml(feature_mode, model)\n",
    "    \n",
    "    X_train_asp = model.preprocess(X_TRAIN_asp, Y_TRAIN_asp)\n",
    "    X_dev_asp = model.preprocess(X_DEV_asp, Y_DEV_asp)\n",
    "        \n",
    "    model.fit(X_train_asp, Y_TRAIN_asp)\n",
    "    \n",
    "    assert all(Y_TRAIN_asp.columns == Y_DEV_asp.columns)\n",
    "    assert all(model.classes == Y_DEV_asp.columns)\n",
    "    \n",
    "    outputs, outputs_prob = model.predict(X_dev_asp)    \n",
    "    utils.get_reports(\n",
    "        y_true = Y_DEV_asp.reset_index(drop=True), \n",
    "        y_pred= outputs\n",
    "    )\n",
    "    return model, (X_train_asp, Y_TRAIN_asp), (X_dev_asp, Y_DEV_sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cad5260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new BOW vectorizer...\n",
      "BOW matrix: (2034, 3570)\n",
      "Creating new models\n",
      "predicting price...\n",
      "predicting food...\n",
      "predicting ambience...\n",
      "predicting service...\n",
      "predicting anecdotes/miscellaneous...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29        71\n",
      "           1       0.62      0.72      0.67       261\n",
      "           2       0.37      0.26      0.31        96\n",
      "           3       0.55      0.56      0.55       134\n",
      "           4       0.66      0.85      0.74       227\n",
      "\n",
      "   micro avg       0.58      0.64      0.61       789\n",
      "   macro avg       0.50      0.53      0.51       789\n",
      "weighted avg       0.56      0.64      0.59       789\n",
      " samples avg       0.61      0.64      0.62       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_asp_bow, train_data_asp, dev_data_asp = gym_aspect_ml(\"BOW\", model=LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a29bdc",
   "metadata": {},
   "source": [
    "## 2.2) Logreg - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce69d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new TFIDF vectorizer...\n",
      "TFIDF matrix: (2034, 3570)\n",
      "Creating new models\n",
      "predicting price...\n",
      "predicting food...\n",
      "predicting ambience...\n",
      "predicting service...\n",
      "predicting anecdotes/miscellaneous...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.16        71\n",
      "           1       0.62      0.83      0.71       261\n",
      "           2       0.54      0.16      0.24        96\n",
      "           3       0.60      0.43      0.50       134\n",
      "           4       0.64      0.85      0.73       227\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       789\n",
      "   macro avg       0.58      0.47      0.47       789\n",
      "weighted avg       0.60      0.62      0.57       789\n",
      " samples avg       0.63      0.63      0.62       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_asp_tfidf, train_data_asp, dev_data_asp = gym_aspect_ml(\"TFIDF\", model=LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba62c22",
   "metadata": {},
   "source": [
    "## 2.3) Bidir-GRU (GloVe) [multiple binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd096dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gym_aspect_dl(\n",
    "    is_bow,\n",
    "    model_template,\n",
    "    compile_info,\n",
    "    epochs = 5,\n",
    "    n_models = 5,  # 5 aspects in total\n",
    "    use_pretrained = True,\n",
    "    X_TRAIN_sent=X_TRAIN_asp, X_DEV_sent=X_DEV_asp, \n",
    "    Y_TRAIN_sent=Y_TRAIN_asp, Y_DEV_sent=Y_DEV_asp, \n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    if use_pretrained:\n",
    "        model = aspect.dl_pretrained(vocab, compile_info, n_models)\n",
    "    else:\n",
    "        model = aspect.dl(compile_info, n_models, is_bow)\n",
    "    \n",
    "    model.set_model_template(model_template)\n",
    "    \n",
    "    X_train_asp,Y_train_asp = model.preprocess(X_TRAIN_asp, Y_TRAIN_asp, **kwargs)\n",
    "    X_dev_asp,Y_dev_asp     = model.preprocess(X_DEV_asp, Y_DEV_asp, **kwargs)\n",
    "\n",
    "    \n",
    "    history = model.fit(\n",
    "                    X_train_asp, Y_train_asp, X_dev_asp, Y_dev_asp,\n",
    "                    batch_size = 32, epochs = epochs\n",
    "                )\n",
    "    assert all(Y_train_asp.columns == Y_dev_asp.columns)\n",
    "    assert all(model.classes == Y_dev_asp.columns)\n",
    "    \n",
    "    outputs, outputs_prob = model.predict(X_dev_asp)        \n",
    "    utils.get_reports(\n",
    "        y_true = Y_DEV_asp.reset_index(drop=True), \n",
    "        y_pred= outputs\n",
    "    )\n",
    "    return model, history, (X_train_asp, Y_train_asp), (X_dev_asp, Y_dev_asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d7e7348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained word embedding\n",
      "fitting price ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 43s 550ms/step - loss: 0.5173 - accuracy: 0.7714 - val_loss: 0.3359 - val_accuracy: 0.9055\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.3824 - accuracy: 0.8776 - val_loss: 0.3312 - val_accuracy: 0.9055\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 33s 508ms/step - loss: 0.3613 - accuracy: 0.8791 - val_loss: 0.3305 - val_accuracy: 0.9015\n",
      "fitting food ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 52s 624ms/step - loss: 0.8263 - accuracy: 0.5757 - val_loss: 0.6366 - val_accuracy: 0.6551\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 35s 553ms/step - loss: 0.6113 - accuracy: 0.6962 - val_loss: 0.5828 - val_accuracy: 0.7403\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 39s 618ms/step - loss: 0.5268 - accuracy: 0.7384 - val_loss: 0.5399 - val_accuracy: 0.7204\n",
      "fitting ambience ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 61s 720ms/step - loss: 0.5777 - accuracy: 0.7763 - val_loss: 0.3971 - val_accuracy: 0.8722\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 37s 576ms/step - loss: 0.4374 - accuracy: 0.8437 - val_loss: 0.3792 - val_accuracy: 0.8722\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 32s 505ms/step - loss: 0.3551 - accuracy: 0.8623 - val_loss: 0.4110 - val_accuracy: 0.8708\n",
      "fitting service ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 47s 542ms/step - loss: 0.5460 - accuracy: 0.7793 - val_loss: 0.6036 - val_accuracy: 0.7590\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 32s 496ms/step - loss: 0.3962 - accuracy: 0.8358 - val_loss: 0.4406 - val_accuracy: 0.8296\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 33s 515ms/step - loss: 0.2859 - accuracy: 0.8859 - val_loss: 0.3839 - val_accuracy: 0.8242\n",
      "fitting anecdotes/miscellaneous ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 46s 586ms/step - loss: 0.7672 - accuracy: 0.6254 - val_loss: 0.5060 - val_accuracy: 0.7124\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 36s 556ms/step - loss: 0.5095 - accuracy: 0.7561 - val_loss: 0.4675 - val_accuracy: 0.7470\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 34s 532ms/step - loss: 0.4506 - accuracy: 0.7901 - val_loss: 0.5078 - val_accuracy: 0.7230\n",
      "predicting price...\n",
      "predicting food...\n",
      "predicting ambience...\n",
      "predicting service...\n",
      "predicting anecdotes/miscellaneous...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.03      0.05        71\n",
      "           1       0.69      0.53      0.60       261\n",
      "           2       0.41      0.18      0.25        96\n",
      "           3       0.51      0.54      0.53       134\n",
      "           4       0.50      0.90      0.64       227\n",
      "\n",
      "   micro avg       0.54      0.55      0.54       789\n",
      "   macro avg       0.46      0.43      0.41       789\n",
      "weighted avg       0.53      0.55      0.51       789\n",
      " samples avg       0.55      0.56      0.55       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_params = dict(\n",
    "    rnn_layers=[128], \n",
    "    dense_layers=[64], \n",
    "    embedding_matrix=embedding_matrix, \n",
    "    n_outputs=1, \n",
    "    embedding_trainable=True,\n",
    "    #vocab_size = vocab_size,\n",
    "    #emb_dim = 256\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "compile_info = dict(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
    "\n",
    "bidir_asp, bidir_asp_hist, train_data_asp, dev_data = gym_aspect_dl(False, get_rnn(**rnn_params), compile_info, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7ed50",
   "metadata": {},
   "source": [
    "## 2.4) CNN (GloVe) [Multiple binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90f71633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting price ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 16s 240ms/step - loss: 0.3824 - accuracy: 0.8899 - val_loss: 0.3206 - val_accuracy: 0.9055\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 14s 224ms/step - loss: 0.3185 - accuracy: 0.8997 - val_loss: 0.3124 - val_accuracy: 0.9055\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 14s 224ms/step - loss: 0.2016 - accuracy: 0.9154 - val_loss: 0.3951 - val_accuracy: 0.8895\n",
      "fitting food ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 17s 244ms/step - loss: 0.6013 - accuracy: 0.6996 - val_loss: 0.6919 - val_accuracy: 0.6671\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 15s 231ms/step - loss: 0.3425 - accuracy: 0.8746 - val_loss: 0.5548 - val_accuracy: 0.7510\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 14s 224ms/step - loss: 0.1948 - accuracy: 0.9371 - val_loss: 0.8611 - val_accuracy: 0.7230\n",
      "fitting ambience ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 17s 245ms/step - loss: 0.4599 - accuracy: 0.8579 - val_loss: 0.3829 - val_accuracy: 0.8722\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 17s 264ms/step - loss: 0.3187 - accuracy: 0.8805 - val_loss: 0.5043 - val_accuracy: 0.8575\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 15s 234ms/step - loss: 0.1652 - accuracy: 0.9444 - val_loss: 0.7595 - val_accuracy: 0.8469\n",
      "fitting service ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 15s 221ms/step - loss: 0.5245 - accuracy: 0.8053 - val_loss: 0.4427 - val_accuracy: 0.8242\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 14s 218ms/step - loss: 0.3088 - accuracy: 0.8845 - val_loss: 0.4312 - val_accuracy: 0.8176\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 16s 257ms/step - loss: 0.1686 - accuracy: 0.9489 - val_loss: 0.5995 - val_accuracy: 0.8083\n",
      "fitting anecdotes/miscellaneous ...\n",
      "\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 16s 234ms/step - loss: 0.6502 - accuracy: 0.6780 - val_loss: 0.4342 - val_accuracy: 0.8069\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 15s 241ms/step - loss: 0.3824 - accuracy: 0.8668 - val_loss: 0.4425 - val_accuracy: 0.7923\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 15s 233ms/step - loss: 0.2214 - accuracy: 0.9169 - val_loss: 0.4879 - val_accuracy: 0.8162\n",
      "predicting price...\n",
      "predicting food...\n",
      "predicting ambience...\n",
      "predicting service...\n",
      "predicting anecdotes/miscellaneous...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.11      0.15        71\n",
      "           1       0.60      0.70      0.64       261\n",
      "           2       0.33      0.28      0.31        96\n",
      "           3       0.46      0.54      0.50       134\n",
      "           4       0.66      0.78      0.72       227\n",
      "\n",
      "   micro avg       0.55      0.59      0.57       789\n",
      "   macro avg       0.46      0.48      0.46       789\n",
      "weighted avg       0.53      0.59      0.55       789\n",
      " samples avg       0.58      0.60      0.58       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, GlobalAveragePooling1D\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "compile_info = dict(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
    "\n",
    "def make_cnnAsp_model(embedding_trainable=False):\n",
    "    filters = 128 \n",
    "    kernel_size = 5 \n",
    "    hidden_dims = 250 \n",
    "    vocab_size, emb_dim = embedding_matrix.shape\n",
    "\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(\n",
    "        Embedding(\n",
    "                input_dim=vocab_size,\n",
    "                output_dim=emb_dim, \n",
    "                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                mask_zero=True,\n",
    "                trainable=embedding_trainable\n",
    "                ) \n",
    "    )\n",
    "    \n",
    "    cnn_model.add(Conv1D(filters,\n",
    "                        kernel_size,\n",
    "                        activation='relu',\n",
    "                        strides=2))\n",
    "\n",
    "    cnn_model.add(GlobalAveragePooling1D())\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    cnn_model.add(Dense(hidden_dims, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return cnn_model\n",
    "\n",
    "cnn_asp, cnn_asp_hist, train_data_asp, dev_data_asp = gym_aspect_dl(False, make_cnnAsp_model(embedding_trainable=True), compile_info, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664b909",
   "metadata": {},
   "source": [
    "## 2.5) bow NN [multi binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5652ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "...Adapting new Tokenizer\n",
      "fitting price ...\n",
      "\n",
      "64/64 [==============================] - 2s 29ms/step - loss: 0.5035 - accuracy: 0.8874 - val_loss: 0.3372 - val_accuracy: 0.8948\n",
      "fitting food ...\n",
      "\n",
      "64/64 [==============================] - 2s 28ms/step - loss: 0.6667 - accuracy: 0.7183 - val_loss: 0.7205 - val_accuracy: 0.7710\n",
      "fitting ambience ...\n",
      "\n",
      "64/64 [==============================] - 3s 31ms/step - loss: 0.6211 - accuracy: 0.8255 - val_loss: 0.4292 - val_accuracy: 0.8695\n",
      "fitting service ...\n",
      "\n",
      "64/64 [==============================] - 3s 32ms/step - loss: 0.7557 - accuracy: 0.8053 - val_loss: 0.6323 - val_accuracy: 0.8469\n",
      "fitting anecdotes/miscellaneous ...\n",
      "\n",
      "64/64 [==============================] - 3s 38ms/step - loss: 0.7868 - accuracy: 0.7301 - val_loss: 0.4440 - val_accuracy: 0.7776\n",
      "predicting price...\n",
      "predicting food...\n",
      "predicting ambience...\n",
      "predicting service...\n",
      "predicting anecdotes/miscellaneous...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.15      0.20        71\n",
      "           1       0.64      0.75      0.69       261\n",
      "           2       0.44      0.19      0.26        96\n",
      "           3       0.59      0.59      0.59       134\n",
      "           4       0.59      0.85      0.70       227\n",
      "\n",
      "   micro avg       0.59      0.63      0.61       789\n",
      "   macro avg       0.51      0.50      0.49       789\n",
      "weighted avg       0.56      0.63      0.58       789\n",
      " samples avg       0.61      0.64      0.61       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_NN_asp(dense_layers):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for units in dense_layers:\n",
    "        model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "compile_info = dict(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
    "nn_bow_asp, nn_bow_asp_hist, train_data_asp, dev_data_asp = gym_aspect_dl('tfidf', get_NN_asp([1200, 200]), compile_info, epochs=1, use_pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9818f9",
   "metadata": {},
   "source": [
    "## 2.5) GRU (GloVe) [1 multi label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b74edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gym_aspect_mulabel(\n",
    "    is_bow,\n",
    "    model_template,\n",
    "    compile_info,\n",
    "    epochs = 5,\n",
    "    use_pretrained = True,\n",
    "    X_TRAIN_asp=X_TRAIN_asp, X_DEV_asp=X_DEV_asp, \n",
    "    Y_TRAIN_asp=Y_TRAIN_asp, Y_DEV_asp=Y_DEV_asp, \n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    if use_pretrained:\n",
    "        model = aspect.mulabel_pretrained(vocab, compile_info, is_bow=None, le=None)\n",
    "    else:\n",
    "        model = aspect.mulabel(compile_info, is_bow)\n",
    "    \n",
    "    model.set_model_template(model_template)\n",
    "    \n",
    "    X_train_asp,Y_train_asp = model.preprocess(X_TRAIN_asp, Y_TRAIN_asp, **kwargs)\n",
    "    X_dev_asp,Y_dev_asp     = model.preprocess(X_DEV_asp, Y_DEV_asp, **kwargs)\n",
    "    \n",
    "    history = model.fit(\n",
    "                    X_train_asp, Y_train_asp, X_dev_asp, Y_dev_asp,\n",
    "                    batch_size = 32, epochs = epochs\n",
    "                )\n",
    "    \n",
    "    outputs, outputs_prob = model.predict(X_dev_asp)        \n",
    "    utils.get_reports(\n",
    "        y_true = Y_dev_asp.reset_index(drop=True), \n",
    "        y_pred= outputs\n",
    "    )\n",
    "    return model, history, (X_train_asp, Y_train_asp), (X_dev_asp, Y_dev_asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da4f9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_models.inference import BaseModel\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout, Conv1D, GlobalMaxPooling1D, BatchNormalization\n",
    "\n",
    "def SigmoidEntropy(y_true, y_pred):\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=tf.cast(y_true,tf.float32))\n",
    "    return tf.reduce_mean(tf.reduce_sum(cross_entropy, axis=1))\n",
    "    \n",
    "def get_gru_mulabel_template(rnn_layers, dense_layers, embedding_matrix, n_outputs, embedding_trainable=False):\n",
    "    model = BaseModel(embedding_matrix, embedding_trainable=embedding_trainable)\n",
    "    \n",
    "    for rnn_unit in rnn_layers[:-1]:\n",
    "        model.add( Bidirectional(GRU(rnn_unit, dropout=0.5, return_sequences=True)) )\n",
    "    model.add( Bidirectional(GRU(rnn_layers[-1], dropout=0.5, return_sequences=False)) )\n",
    "\n",
    "    model.add(BatchNormalization())    \n",
    "    \n",
    "    for dense_unit in dense_layers:\n",
    "        model.add( Dense(dense_unit, activation='relu') )\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add( Dense(n_outputs) )  \n",
    "      \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5cba2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400001, 100)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b262d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained word embedding\n",
      "model is compiled\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 46s 608ms/step - loss: 3.5336 - accuracy: 0.2507 - val_loss: 2.7541 - val_accuracy: 0.4341\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 36s 567ms/step - loss: 2.8722 - accuracy: 0.3702 - val_loss: 2.6182 - val_accuracy: 0.4621\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 36s 562ms/step - loss: 2.5736 - accuracy: 0.4385 - val_loss: 2.4064 - val_accuracy: 0.4794\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 37s 579ms/step - loss: 2.3894 - accuracy: 0.4946 - val_loss: 2.3193 - val_accuracy: 0.4967\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 36s 556ms/step - loss: 2.3035 - accuracy: 0.5088 - val_loss: 2.2026 - val_accuracy: 0.5033\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 38s 595ms/step - loss: 2.1654 - accuracy: 0.5506 - val_loss: 2.2641 - val_accuracy: 0.5060\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 38s 589ms/step - loss: 2.0158 - accuracy: 0.5816 - val_loss: 2.0489 - val_accuracy: 0.5326\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 35s 544ms/step - loss: 2.0060 - accuracy: 0.5855 - val_loss: 2.3089 - val_accuracy: 0.5033\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 37s 580ms/step - loss: 1.8061 - accuracy: 0.6234 - val_loss: 2.2533 - val_accuracy: 0.5126\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 35s 539ms/step - loss: 1.7754 - accuracy: 0.6347 - val_loss: 2.0642 - val_accuracy: 0.5619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.04      0.07        71\n",
      "           1       0.58      0.78      0.67       261\n",
      "           2       0.36      0.19      0.25        96\n",
      "           3       0.48      0.47      0.47       134\n",
      "           4       0.70      0.71      0.71       227\n",
      "\n",
      "   micro avg       0.58      0.57      0.57       789\n",
      "   macro avg       0.47      0.44      0.43       789\n",
      "weighted avg       0.54      0.57      0.54       789\n",
      " samples avg       0.59      0.58      0.58       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_malabel_params = dict(\n",
    "    rnn_layers=[200], \n",
    "    dense_layers=[32], \n",
    "    embedding_matrix=embedding_matrix, \n",
    "    n_outputs=len(Y_TRAIN_asp.columns), \n",
    "    embedding_trainable=True\n",
    "    #vocab_size = vocab_size,\n",
    "    #emb_dim = 256\n",
    ")\n",
    "compile_info = dict(optimizer='adam', loss=SigmoidEntropy, metrics='accuracy')\n",
    "\n",
    "gru_mulabel_template = get_gru_mulabel_template(**gru_malabel_params)\n",
    "gru_mulabel, gru_mulabel_hist, train_data_asp, dev_data_asp = gym_aspect_mulabel(False, gru_mulabel_template, compile_info, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b0109",
   "metadata": {},
   "source": [
    "## 2.6) Bow NN (BOW) [1 multi label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d9840ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_bowNN_asp_mulabel(dense_layers):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for units in dense_layers:\n",
    "        model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(len(Y_TRAIN_asp.columns.unique())))\n",
    "    \n",
    "    return model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "compile_info = dict(optimizer=optimizer, loss=SigmoidEntropy, metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7280dbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is compiled\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "...Adapting new Tokenizer\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 2.4588 - accuracy: 0.4853 - val_loss: 2.0699 - val_accuracy: 0.5619\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 1.3301 - accuracy: 0.7404 - val_loss: 2.4337 - val_accuracy: 0.5846\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.6387 - accuracy: 0.8579 - val_loss: 3.5043 - val_accuracy: 0.5526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.20      0.23        71\n",
      "           1       0.58      0.68      0.63       261\n",
      "           2       0.37      0.27      0.31        96\n",
      "           3       0.46      0.43      0.44       134\n",
      "           4       0.64      0.78      0.70       227\n",
      "\n",
      "   micro avg       0.55      0.57      0.56       789\n",
      "   macro avg       0.47      0.47      0.46       789\n",
      "weighted avg       0.53      0.57      0.54       789\n",
      " samples avg       0.57      0.58      0.57       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_bowNN_asp_mulabel_params = dict(dense_layers=[1000, 258])\n",
    "\n",
    "bowNN_asp_mulabel_template = get_bowNN_asp_mulabel(**get_bowNN_asp_mulabel_params)\n",
    "bowNN_asp_mulabel, bowNN_asp_mulabel_hist, train_data_asp, dev_data_asp = gym_aspect_mulabel('tfidf', bowNN_asp_mulabel_template, compile_info, epochs=3, use_pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb70928",
   "metadata": {},
   "source": [
    "# 3) Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efc3309a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['food', 'price', 'ambience', 'service', 'anecdotes/miscellaneous'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_asp_bow.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b9a6024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting food...\n",
      "predicting price...\n",
      "predicting ambience...\n",
      "predicting service...\n",
      "predicting anecdotes/miscellaneous...\n"
     ]
    }
   ],
   "source": [
    "from my_models import inference\n",
    "\n",
    "inferencer = inference.InferenceModel(tfidf_nn, logreg_asp_tfidf)\n",
    "\n",
    "df_train = pd.read_csv(\"contest1_test.csv\")\n",
    "\n",
    "df_train_inference = df_train[['id','text']]\n",
    "outputs = inferencer.predict(df_train_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "300e5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if use DL as a sent model, run this\n",
    "outputs['polarity'] = outputs['polarity'].apply(lambda x:tfidf_nn.le.inverse_transform([x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3edd7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.to_csv(\"resulting_predictions/test_pred/tfidf_nn_logreg_asp_bow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78ce6c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>food</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>service</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               aspectCategory  polarity\n",
       "id                                     \n",
       "899                      food   neutral\n",
       "899                   service   neutral\n",
       "1349  anecdotes/miscellaneous  positive\n",
       "934                      food  positive\n",
       "2199                     food  positive\n",
       "...                       ...       ...\n",
       "1063  anecdotes/miscellaneous  positive\n",
       "777                      food  positive\n",
       "875   anecdotes/miscellaneous   neutral\n",
       "671                      food  positive\n",
       "617   anecdotes/miscellaneous  positive\n",
       "\n",
       "[472 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b7fc653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1315</td>\n",
       "      <td>Amma has the worst value for money I have expe...</td>\n",
       "      <td>price</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576</td>\n",
       "      <td>By far the best salad I have had in a fast foo...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2850</td>\n",
       "      <td>The food was amazing, the service was so atten...</td>\n",
       "      <td>ambience</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>There was a long wait for a table outside, but...</td>\n",
       "      <td>service</td>\n",
       "      <td>conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>Having hunted around for a quiet, romantic, ye...</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  \\\n",
       "0  1315  Amma has the worst value for money I have expe...   \n",
       "1  2576  By far the best salad I have had in a fast foo...   \n",
       "2  2850  The food was amazing, the service was so atten...   \n",
       "3   301  There was a long wait for a table outside, but...   \n",
       "4    87  Having hunted around for a quiet, romantic, ye...   \n",
       "\n",
       "            aspectCategory  polarity  \n",
       "0                    price  negative  \n",
       "1                     food  positive  \n",
       "2                 ambience  positive  \n",
       "3                  service  conflict  \n",
       "4  anecdotes/miscellaneous   neutral  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST = pd.read_csv(\"DEV.csv\")\n",
    "TEST.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a97fd3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting price...\n",
      "predicting food...\n",
      "predicting ambience...\n",
      "predicting service...\n",
      "predicting anecdotes/miscellaneous...\n"
     ]
    }
   ],
   "source": [
    "logreg_asp_tfidf_input = logreg_asp_tfidf.preprocess(TEST.text)\n",
    "pred, pred_prob = logreg_asp_tfidf.predict(logreg_asp_tfidf_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00d00d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_aspects = []\n",
    "for row in pred.values:\n",
    "    temp = []\n",
    "    for i, p in enumerate(row):\n",
    "        if p > 0:\n",
    "            temp.append(logreg_asp_tfidf.classes[i])\n",
    "    output_aspects.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc526260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1315</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2850</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>1082</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>3243</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>1191</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>1380</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>812</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>789 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  polarity\n",
       "0    1315  negative\n",
       "1    2576  positive\n",
       "2    2850  positive\n",
       "3     301  positive\n",
       "4      87   neutral\n",
       "..    ...       ...\n",
       "784  1082  positive\n",
       "785  3243   neutral\n",
       "786  1191  negative\n",
       "787  1380  positive\n",
       "788   812  positive\n",
       "\n",
       "[789 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sent = pd.read_csv(\"dev_pred_sentiment.csv\")\n",
    "pred_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6bca0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    'id':pred_sent.id,\n",
    "    'aspectCategory': output_aspects,\n",
    "    'polarity': pred_sent.polarity\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d309e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>aspectCategory</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1315</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2850</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2850</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>1082</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>3243</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>1191</td>\n",
       "      <td>food</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>1380</td>\n",
       "      <td>anecdotes/miscellaneous</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>812</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id           aspectCategory  polarity\n",
       "0    1315  anecdotes/miscellaneous  negative\n",
       "1    2576                     food  positive\n",
       "2    2850                     food  positive\n",
       "2    2850                  service  positive\n",
       "3     301                  service  positive\n",
       "..    ...                      ...       ...\n",
       "784  1082                     food  positive\n",
       "785  3243  anecdotes/miscellaneous   neutral\n",
       "786  1191                     food  negative\n",
       "787  1380  anecdotes/miscellaneous  positive\n",
       "788   812                     food  positive\n",
       "\n",
       "[830 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.explode('aspectCategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83b73b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.explode('aspectCategory').to_csv(\"resulting_predictions/dev/bert_logreg_asp_tfidf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73bceeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLASSIFICATION : ASPECT ===\n",
      "                class name  precision  recall  F1-score  support\n",
      "0                     food      0.622   0.831     0.711      261\n",
      "1                    price      0.500   0.099     0.165       71\n",
      "2                  service      0.600   0.425     0.498      134\n",
      "3                 ambience      0.536   0.156     0.242       96\n",
      "4  anecdotes/miscellaneous      0.640   0.846     0.729      227\n",
      "5                MACRO AVG      0.579   0.471     0.469      789\n",
      "6                MICRO AVG      0.621   0.619     0.620      789 \n",
      "\n",
      "=== CLASSIFICATION : SENTIMENT ===\n",
      "  class name  precision  recall  F1-score  support\n",
      "0   positive      0.961   0.941     0.951      440\n",
      "1   negative      0.831   0.983     0.901      175\n",
      "2    neutral      0.925   0.860     0.891      100\n",
      "3   conflict      0.900   0.383     0.537       47\n",
      "4  MACRO AVG      0.904   0.792     0.820      762\n",
      "5  MICRO AVG      0.919   0.906     0.912      762 \n",
      "\n",
      "=== CLASSIFICATION : OVERALL ===\n",
      "              precision  recall  F1-score  support\n",
      "0  MICRO AVG      0.565   0.563     0.564      789 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python evaluate.py DEV.csv resulting_predictions/dev/bert_logreg_asp_tfidf.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99924833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
